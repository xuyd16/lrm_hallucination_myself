# -*- coding: utf-8 -*-

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
import warnings
from typing import Dict, Tuple, Optional, List, Union
from torch.nn.init import xavier_uniform_, constant_

warnings.filterwarnings('ignore')

class ModelConfig:
    """é‡æ„çš„æ¨¡å‹é…ç½®ç±»ï¼Œé€‚é…æ–°çš„æ•°æ®æ ¼å¼"""
    
    def __init__(self):
        # è¾“å…¥å‚æ•° - é‡æ„åçš„æ ¼å¼
        self.num_regions = 5                    # è„‘åŒºæ•°é‡ï¼ˆé¢å¶ã€ä¸­å¤®ã€é¡¶å¶ã€é¢å¶ã€æ•å¶ï¼‰
        self.max_electrodes_per_region = 24     # æ¯ä¸ªè„‘åŒºæœ€å¤§ç”µææ•°
        self.sequence_length = 1600             # æ—¶é—´åºåˆ—é•¿åº¦
        self.embed_dim = 768                    # åµŒå…¥ç»´åº¦
        
        # Transformeræ¶æ„å‚æ•°
        self.num_heads = 24                      # æ³¨æ„åŠ›å¤´æ•°
        self.depth = 24                          # Transformerå±‚æ•°
        self.mlp_ratio = 4.0                    # MLPéšè—å±‚æ¯”ä¾‹
        
        # æ­£åˆ™åŒ–å‚æ•°
        self.drop_rate = 0.1                    # Dropoutç‡
        self.attn_drop_rate = 0.1              # æ³¨æ„åŠ›Dropoutç‡
        self.drop_path_rate = 0.1              # éšæœºæ·±åº¦ç‡
        
        # ä½ç½®ç¼–ç å‚æ•°
        self.use_abs_pos = True                 # æ˜¯å¦ä½¿ç”¨ç»å¯¹ä½ç½®ç¼–ç 
        self.use_rel_pos = False                # æ˜¯å¦ä½¿ç”¨ç›¸å¯¹ä½ç½®ç¼–ç 
        self.use_time_embed = True              # æ˜¯å¦ä½¿ç”¨æ—¶é—´åµŒå…¥
        
        # æ©ç å‚æ•°
        self.mask_ratio = 0.15                  # æ—¶åŸŸæ©ç æ¯”ä¾‹
        self.freq_mask_ratio = 0.3             # é¢‘åŸŸæ©ç æ¯”ä¾‹
        self.mask_strategy = 'random'           # æ©ç ç­–ç•¥
        self.mask_noise_ratio = 0.005          # æ©ç å™ªå£°æ¯”ä¾‹
        
        # MoEå‚æ•°
        self.use_moe = True                     # æ˜¯å¦ä½¿ç”¨MoE
        self.num_experts = 16                   # ä¸“å®¶æ•°é‡
        self.top_k_experts = 2                  # æ¿€æ´»çš„ä¸“å®¶æ•°é‡
        self.moe_aux_loss_coeff = 0.01         # MoEè¾…åŠ©æŸå¤±ç³»æ•°
        
        # é¢‘åŸŸå¤„ç†å‚æ•°
        self.n_freq_bands = 5                   # é¢‘å¸¦æ•°é‡
        self.freq_loss_weight = 0.1            # é¢‘åŸŸæŸå¤±æƒé‡ï¼ˆä»0.3é™ä½åˆ°0.1ï¼‰
        self.time_loss_weight = 0.9            # æ—¶åŸŸæŸå¤±æƒé‡ï¼ˆä»0.7æé«˜åˆ°0.9ï¼‰
        
        # è®­ç»ƒå‚æ•°
        self.lr = 1e-4                         # å­¦ä¹ ç‡
        self.weight_decay = 1e-4               # æƒé‡è¡°å‡
        self.warmup_epochs = 5                 # é¢„çƒ­è½®æ•°
        self.use_amp = True                    # æ··åˆç²¾åº¦è®­ç»ƒ
        self.clip_grad = 1.0                   # æ¢¯åº¦è£å‰ª
        self.batch_size = 32                   # æ‰¹æ¬¡å¤§å°
        
        # æ•°æ®æ ‡å‡†åŒ–å‚æ•°
        self.use_layer_norm = True             # æ˜¯å¦ä½¿ç”¨å±‚å½’ä¸€åŒ–
        self.use_batch_norm = True             # æ˜¯å¦ä½¿ç”¨æ‰¹å½’ä¸€åŒ–
        self.eps = 1e-6                       # æ•°å€¼ç¨³å®šæ€§å‚æ•°
        
        # åˆå§‹åŒ–å‚æ•°
        self.init_std = 0.02                   # åˆå§‹åŒ–æ ‡å‡†å·®
        
        # è„‘åŒºå’Œç”µæç›¸å…³é…ç½®
        self.electrode_names = [               # é»˜è®¤ç”µæåç§°ï¼ˆç”¨äºè°ƒè¯•å’Œå¯è§†åŒ–ï¼‰
            'Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'Fz',
            'C3', 'C4', 'Cz', 'P3', 'P4', 'P7', 'P8', 'Pz',
            'O1', 'O2', 'Oz', 'T3', 'T4', 'T5', 'T6'
        ]
        
        self.region_names = ['frontal', 'central', 'parietal', 'temporal', 'occipital']
        
        # è°ƒè¯•å‚æ•°
        self.debug = False                     # è°ƒè¯•æ¨¡å¼
        self.freq_eval = True                  # é¢‘åŸŸè¯„ä¼°


class EEGRegionProjection(nn.Module):
    """
    ç®€åŒ–çš„EEGè„‘åŒºæŠ•å½±å±‚ï¼Œæ›¿æ¢åŸæ¥çš„DualDomainProjection
    å°†[B, R, E, T]æ ¼å¼çš„è¾“å…¥è½¬æ¢ä¸ºTransformeréœ€è¦çš„åºåˆ—æ ¼å¼
    """
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.config = config
        self.num_regions = config.num_regions
        self.max_electrodes_per_region = config.max_electrodes_per_region
        self.sequence_length = config.sequence_length
        self.embed_dim = config.embed_dim
        
        # æ—¶é—´æŠ•å½±å±‚ - å°†æ—¶é—´åºåˆ—æŠ•å½±åˆ°åµŒå…¥ç©ºé—´
        self.time_projection = nn.Sequential(
            nn.Conv1d(1, config.embed_dim // 4, kernel_size=7, padding=3),
            nn.BatchNorm1d(config.embed_dim // 4),
            nn.ReLU(inplace=True),
            nn.Conv1d(config.embed_dim // 4, config.embed_dim // 2, kernel_size=5, padding=2),
            nn.BatchNorm1d(config.embed_dim // 2),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(config.embed_dim // 2, config.embed_dim)
        )
        
        # é¢‘åŸŸç‰¹å¾æå–
        # é˜²æŠ¤æ£€æŸ¥ï¼šç¡®ä¿n_freq_bandsè‡³å°‘ä¸º1ï¼Œç”¨äºåˆ›å»ºæœ‰æ•ˆçš„å‚æ•°å’Œå±‚
        effective_n_freq_bands = max(1, config.n_freq_bands)
        self.freq_bands = nn.Parameter(
            torch.linspace(0.5, 50, effective_n_freq_bands + 1)
        )  # é¢‘å¸¦è¾¹ç•Œ
        
        # é¢‘åŸŸæŠ•å½±å±‚
        self.freq_projection = nn.Sequential(
            nn.Linear(effective_n_freq_bands, config.embed_dim // 2),
            nn.ReLU(inplace=True),
            nn.Linear(config.embed_dim // 2, config.embed_dim)
        )
        
        # åŸå§‹ä¿¡å·æŠ•å½±ï¼ˆç”¨äºé‡å»ºä»»åŠ¡ï¼‰
        self.raw_projection = nn.Sequential(
            nn.Linear(config.sequence_length, config.embed_dim * 2),
            nn.ReLU(inplace=True),
            nn.Dropout(config.drop_rate),
            nn.Linear(config.embed_dim * 2, config.embed_dim)
        )
        
        # å±‚å½’ä¸€åŒ–
        self.layer_norm = nn.LayerNorm(config.embed_dim)
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æŠ•å½±å±‚æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                xavier_uniform_(module.weight)
                if module.bias is not None:
                    constant_(module.bias, 0)
            elif isinstance(module, nn.Conv1d):
                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
    
    def forward(self, x: torch.Tensor, padding_mask: torch.Tensor = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥æ•°æ® [B, R, E, T]
            padding_mask: å¡«å……æ©ç  [B, R, E]ï¼ŒTrueè¡¨ç¤ºå¡«å……ä½ç½®
            
        Returns:
            time_features: æ—¶åŸŸç‰¹å¾ [B, R*E, D]
            freq_features: é¢‘åŸŸç‰¹å¾ [B, R*E, D] 
            raw_features: åŸå§‹ä¿¡å·ç‰¹å¾ [B, R*E, D]
        """
        B, R, E, T = x.shape
        
        # é‡æ–°å¡‘å½¢ä¸º [B*R*E, T]ï¼Œå°†æ¯ä¸ªç”µæçš„æ—¶é—´åºåˆ—è§†ä¸ºç‹¬ç«‹æ ·æœ¬
        x_reshaped = x.view(B * R * E, T)
        
        # å¤„ç†padding mask
        if padding_mask is not None:
            mask_reshaped = padding_mask.view(B * R * E)
            # å°†å¡«å……ä½ç½®çš„æ•°æ®ç½®é›¶
            x_reshaped = x_reshaped * (~mask_reshaped).float().unsqueeze(-1)
        
        # æ—¶åŸŸç‰¹å¾æå–
        time_features = self.time_projection(x_reshaped.unsqueeze(1))  # [B*R*E, 1, T] -> [B*R*E, D]
        
        # é¢‘åŸŸç‰¹å¾æå–
        freq_features = self._extract_frequency_features(x_reshaped)  # [B*R*E, D]
        
        # åŸå§‹ä¿¡å·æŠ•å½±ï¼ˆç”¨äºé‡å»ºï¼‰
        raw_features = self.raw_projection(x_reshaped)  # [B*R*E, D]
        
        # åº”ç”¨å±‚å½’ä¸€åŒ–
        time_features = self.layer_norm(time_features)
        freq_features = self.layer_norm(freq_features)
        raw_features = self.layer_norm(raw_features)
        
        # é‡æ–°å¡‘å½¢ä¸ºåºåˆ—æ ¼å¼ [B, R*E, D]
        seq_len = R * E
        time_features = time_features.view(B, seq_len, self.embed_dim)
        freq_features = freq_features.view(B, seq_len, self.embed_dim)
        raw_features = raw_features.view(B, seq_len, self.embed_dim)
        
        return time_features, freq_features, raw_features
    
    def _extract_frequency_features(self, x: torch.Tensor) -> torch.Tensor:
        """
        æå–é¢‘åŸŸç‰¹å¾
        
        Args:
            x: è¾“å…¥æ—¶é—´åºåˆ— [B*R*E, T]
            
        Returns:
            freq_features: é¢‘åŸŸç‰¹å¾ [B*R*E, D]
        """
        # ä½¿ç”¨float32è¿›è¡ŒFFTè®¡ç®—ä»¥é¿å…cuFFTçš„half precisioné™åˆ¶
        with torch.cuda.amp.autocast(enabled=False):
            x_float = x.float()  # ç¡®ä¿è¾“å…¥ä¸º float32
            
            # è®¡ç®—FFT
            fft_result = torch.fft.rfft(x_float, dim=-1)
            power_spectrum = torch.abs(fft_result) ** 2
            
            # è®¡ç®—é¢‘ç‡è½´
            freqs = torch.fft.rfftfreq(x_float.size(-1), device=x.device) * 250  # å‡è®¾é‡‡æ ·ç‡250Hz
            
            # æŒ‰é¢‘å¸¦æå–ç‰¹å¾
            band_powers = []
            # é˜²æŠ¤æ£€æŸ¥ï¼šç¡®ä¿n_freq_bandsè‡³å°‘ä¸º1
            if self.config.n_freq_bands <= 0:
                # å¦‚æœé¢‘å¸¦æ•°ä¸º0ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„é¢‘å¸¦ç‰¹å¾
                band_power = power_spectrum.mean(dim=-1)  # ä½¿ç”¨æ•´ä¸ªé¢‘è°±çš„å¹³å‡å€¼
                band_powers.append(band_power)
            else:
                for i in range(self.config.n_freq_bands):
                    band_mask = (freqs >= self.freq_bands[i]) & (freqs < self.freq_bands[i + 1])
                    if band_mask.any():
                        band_power = power_spectrum[:, band_mask].mean(dim=-1)
                    else:
                        band_power = torch.zeros(power_spectrum.size(0), device=x.device)
                    band_powers.append(band_power)
            
            # å †å é¢‘å¸¦ç‰¹å¾
            band_features = torch.stack(band_powers, dim=-1)  # [B*R*E, n_freq_bands]
            
            # é€šè¿‡é¢‘åŸŸæŠ•å½±å±‚ï¼ˆä¹Ÿåœ¨float32ä¸Šä¸‹æ–‡ä¸­ï¼‰
            freq_features = self.freq_projection(band_features)  # [B*R*E, D]
        
        return freq_features


class CrossAttentionFusion(nn.Module):
    """
    åŒå‘äº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—
    - Time features query Frequency features
    - Frequency features query Time features
    - æœ€ç»ˆå°†èåˆåçš„ä¸¤ä¸ªç‰¹å¾æµè¿›è¡Œåˆå¹¶
    """
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.config = config
        embed_dim = config.embed_dim
        num_heads = config.num_heads
        mlp_ratio = config.mlp_ratio
        drop_rate = config.drop_rate

        # æ—¶é—´ç‰¹å¾ -> æŸ¥è¯¢Q, é¢‘ç‡ç‰¹å¾ -> é”®K/å€¼V
        self.t_q_f_kv_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=drop_rate, batch_first=True)
        self.norm1_t = nn.LayerNorm(embed_dim)
        self.mlp_t = nn.Sequential(
            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),
            nn.GELU(),
            nn.Dropout(drop_rate),
            nn.Linear(int(embed_dim * mlp_ratio), embed_dim)
        )
        self.norm2_t = nn.LayerNorm(embed_dim)

        # é¢‘ç‡ç‰¹å¾ -> æŸ¥è¯¢Q, æ—¶é—´ç‰¹å¾ -> é”®K/å€¼V
        self.f_q_t_kv_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=drop_rate, batch_first=True)
        self.norm1_f = nn.LayerNorm(embed_dim)
        self.mlp_f = nn.Sequential(
            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),
            nn.GELU(),
            nn.Dropout(drop_rate),
            nn.Linear(int(embed_dim * mlp_ratio), embed_dim)
        )
        self.norm2_f = nn.LayerNorm(embed_dim)

        # æœ€ç»ˆèåˆæŠ•å½±å±‚
        self.final_proj = nn.Linear(embed_dim * 2, embed_dim)
        self.final_norm = nn.LayerNorm(embed_dim)

    def forward(self, x_time: torch.Tensor, x_freq: torch.Tensor) -> torch.Tensor:
        # x_time å’Œ x_freq çš„å½¢çŠ¶å‡ä¸º [B, L, D]
        
        # 1. æ—¶é—´æŸ¥è¯¢é¢‘ç‡
        t_norm = self.norm1_t(x_time)
        f_norm = self.norm1_f(x_freq)
        # æ—¶é—´ç‰¹å¾ä»é¢‘ç‡ç‰¹å¾ä¸­å¸å–ä¿¡æ¯
        fused_t, _ = self.t_q_f_kv_attn(query=t_norm, key=f_norm, value=f_norm)
        x_time = x_time + fused_t # æ®‹å·®è¿æ¥
        x_time = x_time + self.mlp_t(self.norm2_t(x_time)) # FFN

        # 2. é¢‘ç‡æŸ¥è¯¢æ—¶é—´ (ä½¿ç”¨åŸå§‹çš„x_timeä½œä¸ºKey/Valueä»¥è·å¾—æœ€åŸå§‹ä¿¡æ¯)
        t_norm = self.norm1_t(x_time) # é‡æ–°norm
        f_norm = self.norm1_f(x_freq)
        # é¢‘ç‡ç‰¹å¾ä»æ—¶é—´ç‰¹å¾ä¸­å¸å–ä¿¡æ¯
        fused_f, _ = self.f_q_t_kv_attn(query=f_norm, key=t_norm, value=t_norm)
        x_freq = x_freq + fused_f # æ®‹å·®è¿æ¥
        x_freq = x_freq + self.mlp_f(self.norm2_f(x_freq)) # FFN

        # 3. æœ€ç»ˆèåˆ
        # å°†ä¸¤ä¸ªç»è¿‡æ·±åº¦äº¤äº’çš„ç‰¹å¾æµæ‹¼æ¥èµ·æ¥
        final_fused = torch.cat([x_time, x_freq], dim=-1) # -> [B, L, 2*D]
        # æŠ•å½±å›åŸå§‹ç»´åº¦
        projected_fused = self.final_proj(final_fused) # -> [B, L, D]
        
        return self.final_norm(projected_fused)


class MoELayer(nn.Module):
    """æ··åˆä¸“å®¶å±‚ï¼ˆä¿æŒä¸å˜ï¼Œä½†ç®€åŒ–æ³¨é‡Šï¼‰"""
    
    def __init__(self, config: ModelConfig, input_dim: int):
        super().__init__()
        self.config = config
        self.num_experts = config.num_experts
        self.top_k = config.top_k_experts
        self.input_dim = input_dim
        self.hidden_dim = int(input_dim * config.mlp_ratio)
        
        # é—¨æ§ç½‘ç»œ
        self.gate = nn.Linear(input_dim, self.num_experts, bias=False)
        
        # ä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(input_dim, self.hidden_dim),
                nn.ReLU(inplace=True),
                nn.Dropout(config.drop_rate),
                nn.Linear(self.hidden_dim, input_dim)
            ) for _ in range(self.num_experts)
        ])
        
        self._init_weights()
    
    def _init_weights(self):
        nn.init.xavier_uniform_(self.gate.weight)
        for expert in self.experts:
            for layer in expert:
                if isinstance(layer, nn.Linear):
                    xavier_uniform_(layer.weight)
                    if layer.bias is not None:
                        constant_(layer.bias, 0)

    def forward(self, x: torch.Tensor):
        batch_size, seq_len, input_dim = x.shape
        x_flat = x.view(-1, input_dim)
        
        # é—¨æ§è®¡ç®—
        gate_logits = self.gate(x_flat)  # [B*L, E]
        gate_probs = F.softmax(gate_logits, dim=-1)
        
        # Top-Ké€‰æ‹©
        topk_probs, topk_indices = torch.topk(gate_probs, self.top_k, dim=-1)
        topk_probs = topk_probs / topk_probs.sum(dim=-1, keepdim=True)  # é‡æ–°å½’ä¸€åŒ–
        
        # è®¡ç®—ä¸“å®¶è¾“å‡º
        output = torch.zeros_like(x_flat)
        for i in range(self.top_k):
            expert_indices = topk_indices[:, i]
            expert_probs = topk_probs[:, i].unsqueeze(-1)
            
            for expert_id in range(self.num_experts):
                mask = (expert_indices == expert_id)
                if mask.any():
                    expert_input = x_flat[mask]
                    expert_output = self.experts[expert_id](expert_input)
                    output[mask] += expert_probs[mask] * expert_output
        
        # è®¡ç®—è¾…åŠ©æŸå¤±ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
        aux_loss = self._compute_aux_loss(gate_probs)
        
        return output.view(batch_size, seq_len, input_dim), aux_loss
    
    def _compute_aux_loss(self, gate_probs: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—è´Ÿè½½å‡è¡¡è¾…åŠ©æŸå¤±"""
        mean_prob = gate_probs.mean(dim=0)  # [E]
        mean_prob_topk = (gate_probs > gate_probs.topk(self.top_k, dim=-1)[0][..., -1:]).float().mean(dim=0)
        aux_loss = torch.sum(mean_prob * mean_prob_topk) * self.num_experts
        return aux_loss


class RotaryPositionEncoding(nn.Module):
    """æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆä¿æŒä¸å˜ï¼‰"""
    
    def __init__(self, dim: int, max_seq_len: int = 2048):
        super().__init__()
        self.dim = dim
        self.max_seq_len = max_seq_len
        
        # é¢„è®¡ç®—æ—‹è½¬è§’åº¦
        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))
        self.register_buffer('inv_freq', inv_freq)
        
        # é¢„è®¡ç®—ä½ç½®ç¼–ç 
        t = torch.arange(max_seq_len, dtype=torch.float)
        freqs = torch.outer(t, inv_freq)
        emb = torch.cat((freqs, freqs), dim=-1)
        self.register_buffer('cos_cached', emb.cos())
        self.register_buffer('sin_cached', emb.sin())
    
    def rotate_half(self, x):
        x1, x2 = x[..., :x.shape[-1]//2], x[..., x.shape[-1]//2:]
        return torch.cat((-x2, x1), dim=-1)
    
    def apply_rotary_pos_emb(self, q: torch.Tensor, k: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç """
        seq_len = q.shape[-2]
        cos = self.cos_cached[:seq_len]
        sin = self.sin_cached[:seq_len]
        
        q_embed = (q * cos) + (self.rotate_half(q) * sin)
        k_embed = (k * cos) + (self.rotate_half(k) * sin)
        
        return q_embed, k_embed


class TransformerBlock(nn.Module):
    """Transformerå—ï¼ˆä¿æŒä¸»è¦ç»“æ„ï¼Œç®€åŒ–æ³¨é‡Šï¼‰"""
    
    def __init__(self, config: ModelConfig, layer_idx: int):
        super().__init__()
        self.config = config
        self.layer_idx = layer_idx
        self.embed_dim = config.embed_dim
        self.num_heads = config.num_heads
        self.head_dim = self.embed_dim // self.num_heads
        
        # å¤šå¤´æ³¨æ„åŠ›
        self.qkv_proj = nn.Linear(self.embed_dim, 3 * self.embed_dim, bias=False)
        self.attn_drop = nn.Dropout(config.attn_drop_rate)
        self.proj = nn.Linear(self.embed_dim, self.embed_dim)
        self.proj_drop = nn.Dropout(config.drop_rate)
        
        # å±‚å½’ä¸€åŒ–
        self.norm1 = nn.LayerNorm(self.embed_dim, eps=config.eps)
        self.norm2 = nn.LayerNorm(self.embed_dim, eps=config.eps)
        
        # ä½ç½®ç¼–ç 
        if config.use_rel_pos:
            self.rotary_pos_emb = RotaryPositionEncoding(self.head_dim)
        
        # FFNæˆ–MoE
        if config.use_moe:
            self.mlp = MoELayer(config, self.embed_dim)
        else:
            mlp_hidden_dim = int(self.embed_dim * config.mlp_ratio)
            self.mlp = nn.Sequential(
                nn.Linear(self.embed_dim, mlp_hidden_dim),
                nn.GELU(),
                nn.Dropout(config.drop_rate),
                nn.Linear(mlp_hidden_dim, self.embed_dim),
                nn.Dropout(config.drop_rate)
            )
            
        # éšæœºæ·±åº¦
        self.drop_path_rate = config.drop_path_rate * layer_idx / max(config.depth - 1, 1)
            
        self._init_weights()

    def _init_weights(self):
        for module in self.modules():
            if isinstance(module, nn.Linear):
                xavier_uniform_(module.weight)
                if module.bias is not None:
                    constant_(module.bias, 0)

    def forward(self, x: torch.Tensor, 
               attn_mask: Optional[torch.Tensor] = None,
               key_padding_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        
        B, L, D = x.shape
        
        # å¤šå¤´æ³¨æ„åŠ›
        residual = x
        x = self.norm1(x)
        
        qkv = self.qkv_proj(x).reshape(B, L, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)
        q, k, v = qkv.unbind(0)
        
        # åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç 
        if hasattr(self, 'rotary_pos_emb'):
            q, k = self.rotary_pos_emb.apply_rotary_pos_emb(q, k)
        
        # è®¡ç®—æ³¨æ„åŠ›
        attn_output, aux_loss = self._attention(q, k, v, attn_mask, key_padding_mask)
        
        # æŠ•å½±å’Œæ®‹å·®è¿æ¥
        attn_output = self.proj(attn_output)
        attn_output = self.proj_drop(attn_output)
        
        # éšæœºæ·±åº¦
        if self.training and self.drop_path_rate > 0:
            if torch.rand(1) < self.drop_path_rate:
                attn_output = attn_output * 0
        
        x = residual + attn_output
        
        # MLP
        residual = x
        x = self.norm2(x)
        
        if self.config.use_moe:
            mlp_output, moe_aux_loss = self.mlp(x)
            aux_loss = aux_loss + moe_aux_loss if aux_loss is not None else moe_aux_loss
        else:
            mlp_output = self.mlp(x)
        
        # éšæœºæ·±åº¦
        if self.training and self.drop_path_rate > 0:
            if torch.rand(1) < self.drop_path_rate:
                mlp_output = mlp_output * 0
        
        x = residual + mlp_output
        
        return x, aux_loss
    
    def _attention(self, q, k, v, attn_mask=None, key_padding_mask=None):
        B, H, L, D = q.shape
        scale = D ** -0.5
        
        attn = torch.matmul(q, k.transpose(-2, -1)) * scale
        
        # åº”ç”¨æ©ç 
        if key_padding_mask is not None:
            # key_padding_mask: [B, L], Trueè¡¨ç¤ºéœ€è¦è¢«æ©ç›–çš„ä½ç½®
            attn = attn.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf'))
        
        if attn_mask is not None:
            attn = attn.masked_fill(attn_mask, float('-inf'))
        
        attn = F.softmax(attn, dim=-1)
        attn = self.attn_drop(attn)
        
        output = torch.matmul(attn, v).transpose(1, 2).reshape(B, L, self.embed_dim)
        
        return output, None


class DualDomainTransformerMEM(nn.Module):
    """
    é‡æ„çš„åŒåŸŸTransformeræ¨¡å‹
    æ”¯æŒæ–°çš„[B,R,E,T]è¾“å…¥æ ¼å¼å’Œpadding mask
    """
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.config = config
        self.num_regions = config.num_regions
        self.max_electrodes_per_region = config.max_electrodes_per_region
        self.embed_dim = config.embed_dim
        
        # è¾“å…¥æŠ•å½±å±‚ï¼ˆæ›¿æ¢åŸæ¥çš„DualDomainProjectionï¼‰
        self.region_projection = EEGRegionProjection(config)
        
        # (æ–°å¢) äº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—
        self.fusion_module = CrossAttentionFusion(config)
        
        # ä½ç½®åµŒå…¥ - ç®€åŒ–ç‰ˆæœ¬
        # è„‘åŒºä½ç½®åµŒå…¥
        self.region_embedding = nn.Embedding(config.num_regions, config.embed_dim)
        # è„‘åŒºå†…ç”µæä½ç½®åµŒå…¥
        self.intra_region_pos_embedding = nn.Embedding(config.max_electrodes_per_region, config.embed_dim)
        
        # (æ–°å¢) åºåˆ—ä½ç½®åµŒå…¥
        # åºåˆ—é•¿åº¦ä¸º R * E = 5 * 24 = 120
        self.positional_embedding = nn.Embedding(config.num_regions * config.max_electrodes_per_region, config.embed_dim)
        
        # (æ–°å¢) æ·»åŠ ä¸€ä¸ªå¯å­¦ä¹ çš„ [MASK] Token
        self.mask_token = nn.Parameter(torch.zeros(1, 1, config.embed_dim))
        
        # Transformerå±‚
        self.layers = nn.ModuleList([
            TransformerBlock(config, i) for i in range(config.depth)
        ])
        
        # è¾“å‡ºå±‚å½’ä¸€åŒ–
        self.norm = nn.LayerNorm(config.embed_dim, eps=config.eps)
        
        # é‡å»ºå¤´
        # æ—¶åŸŸé‡å»ºå¤´
        self.time_reconstruction_head1 = nn.Linear(config.embed_dim, config.sequence_length)
        self.time_reconstruction_head2 = nn.Linear(config.embed_dim, config.sequence_length)
        
        # é¢‘åŸŸé‡å»ºå¤´
        # é˜²æŠ¤æ£€æŸ¥ï¼šç¡®ä¿n_freq_bandsè‡³å°‘ä¸º1ï¼Œç”¨äºåˆ›å»ºæœ‰æ•ˆçš„å±‚
        effective_n_freq_bands = max(1, config.n_freq_bands)
        self.freq_reconstruction_head1 = nn.Linear(config.embed_dim, effective_n_freq_bands)
        self.freq_reconstruction_head2 = nn.Linear(config.embed_dim, effective_n_freq_bands)
        
        # Dropout
        self.dropout = nn.Dropout(config.drop_rate)
        
        self._init_weights()
        
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                xavier_uniform_(module.weight)
                if module.bias is not None:
                    constant_(module.bias, 0)
            elif isinstance(module, nn.Embedding):
                nn.init.normal_(module.weight, std=self.config.init_std)
            elif isinstance(module, nn.LayerNorm):
                nn.init.constant_(module.weight, 1.0)
                nn.init.constant_(module.bias, 0.0)
        
        # (æ–°å¢) å¯¹ mask_token è¿›è¡Œåˆå§‹åŒ–
        if hasattr(self, 'mask_token'):
            nn.init.normal_(self.mask_token, std=self.config.init_std)
    
    def forward(self, x: torch.Tensor, 
                time_mask: Optional[torch.Tensor] = None,
                     freq_mask: Optional[torch.Tensor] = None,
                padding_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥æ•°æ® [B, R, E, T]
            time_mask: æ—¶åŸŸæ©ç  [B, R*E] (å¯é€‰)
            freq_mask: é¢‘åŸŸæ©ç  [B, n_freq_bands] (å¯é€‰)
            padding_mask: å¡«å……æ©ç  [B, R, E], Trueè¡¨ç¤ºå¡«å……ä½ç½®
            
        Returns:
            time_pred1: æ—¶åŸŸé¢„æµ‹1 [B, R*E, T]
            time_pred2: æ—¶åŸŸé¢„æµ‹2 [B, R*E, T]  
            freq_pred1: é¢‘åŸŸé¢„æµ‹1 [B, R*E, n_freq_bands]
            freq_pred2: é¢‘åŸŸé¢„æµ‹2 [B, R*E, n_freq_bands]
            moe_aux_loss: MoEè¾…åŠ©æŸå¤±
        """
        B, R, E, T = x.shape
        seq_len = R * E
        
        # 1. æŠ•å½±åˆ°ç‰¹å¾ç©ºé—´ (å¹¶è¡Œè®¡ç®—æ—¶åŸŸå’Œé¢‘åŸŸç‰¹å¾)
        time_features, freq_features, raw_features = self.region_projection(x, padding_mask)
        # -> è¾“å‡ºå½¢çŠ¶: [B, 120, D]

        # 2. (æ ¸å¿ƒä¿®æ”¹) ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›è¿›è¡Œæ·±åº¦èåˆ
        fused_features = self.fusion_module(time_features, freq_features)
        
        # 3. (æ ¸å¿ƒä¿®æ”¹) æ³¨å…¥æ‰€æœ‰ç»“æ„åŒ–åµŒå…¥
        # 3a. ç©ºé—´ç»“æ„åµŒå…¥
        region_ids = torch.arange(R, device=x.device).repeat_interleave(E).unsqueeze(0).expand(B, -1)
        electrode_ids = torch.arange(E, device=x.device).repeat(R).unsqueeze(0).expand(B, -1)
        region_emb = self.region_embedding(region_ids)
        electrode_emb = self.intra_region_pos_embedding(electrode_ids)
        
        # 3b. åºåˆ—ä½ç½®åµŒå…¥
        position_ids = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(B, -1)
        pos_emb = self.positional_embedding(position_ids)
        
        # å°†èåˆåçš„ç‰¹å¾ä¸æ‰€æœ‰åµŒå…¥ç›¸åŠ 
        x_embedded = fused_features + region_emb + electrode_emb + pos_emb
        x_embedded = self.dropout(x_embedded)
        
        # 4. å¤„ç†padding mask (ä¿æŒä¸å˜)
        if padding_mask is not None:
            key_padding_mask = padding_mask.view(B, seq_len)
        else:
            key_padding_mask = None
            
        # 5. æ©ç è‡ªç¼–ç åº”ç”¨ (ä¿æŒä¸å˜)
        if time_mask is not None:
            mask = time_mask.unsqueeze(-1)
            x_embedded = torch.where(mask, self.mask_token, x_embedded)

        # 6. é€šè¿‡Transformerå±‚ (ä¿æŒä¸å˜)
        total_aux_loss = 0
        for layer in self.layers:
            x_embedded, aux_loss = layer(
                x_embedded, 
                attn_mask=None,
                key_padding_mask=key_padding_mask
            )
            if aux_loss is not None:
                total_aux_loss += aux_loss
        
        # 7. åç»­æ­¥éª¤ (å±‚å½’ä¸€åŒ–å’Œé‡å»º) ä¿æŒä¸å˜
        x_embedded = self.norm(x_embedded)
        time_pred1 = self.time_reconstruction_head1(x_embedded)
        time_pred2 = self.time_reconstruction_head2(x_embedded)
        freq_pred1 = self.freq_reconstruction_head1(x_embedded)
        freq_pred2 = self.freq_reconstruction_head2(x_embedded)
        
        return time_pred1, time_pred2, freq_pred1, freq_pred2, total_aux_loss
    
    def get_targets(self, x: torch.Tensor, padding_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """è·å–è®­ç»ƒç›®æ ‡"""
        B, R, E, T = x.shape
        
        # æ—¶åŸŸç›®æ ‡ï¼šç›´æ¥é‡å¡‘è¾“å…¥
        time_targets = x.view(B, R * E, T)
        
        # é¢‘åŸŸç›®æ ‡ï¼šæå–é¢‘åŸŸç‰¹å¾
        x_flat = x.view(B * R * E, T)
        
        # ä½¿ç”¨float32è¿›è¡ŒFFTè®¡ç®—ä»¥é¿å…cuFFTçš„half precisioné™åˆ¶
        with torch.cuda.amp.autocast(enabled=False):
            x_flat_float = x_flat.float()  # ç¡®ä¿è¾“å…¥ä¸º float32
            
            # è®¡ç®—FFT
            fft_result = torch.fft.rfft(x_flat_float, dim=-1)
            power_spectrum = torch.abs(fft_result) ** 2
            
            # è®¡ç®—é¢‘ç‡è½´
            freqs = torch.fft.rfftfreq(T, device=x.device) * 250  # å‡è®¾é‡‡æ ·ç‡250Hz
            
            # æŒ‰é¢‘å¸¦æå–ç‰¹å¾
            band_powers = []
            # é˜²æŠ¤æ£€æŸ¥ï¼šç¡®ä¿n_freq_bandsè‡³å°‘ä¸º1
            effective_n_freq_bands = max(1, self.config.n_freq_bands)
            if self.config.n_freq_bands <= 0:
                # å¦‚æœé¢‘å¸¦æ•°ä¸º0ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„é¢‘å¸¦ç‰¹å¾
                band_power = power_spectrum.mean(dim=-1)  # ä½¿ç”¨æ•´ä¸ªé¢‘è°±çš„å¹³å‡å€¼
                band_powers.append(band_power)
            else:
                freq_bands = torch.linspace(0.5, 50, effective_n_freq_bands + 1, device=x.device)
                for i in range(effective_n_freq_bands):
                    band_mask = (freqs >= freq_bands[i]) & (freqs < freq_bands[i + 1])
                    if band_mask.any():
                        band_power = power_spectrum[:, band_mask].mean(dim=-1)
                    else:
                        band_power = torch.zeros(power_spectrum.size(0), device=x.device)
                    band_powers.append(band_power)  # ä¿®å¤ç¼©è¿›é”™è¯¯ï¼šè¿™è¡Œåº”è¯¥åœ¨å¾ªç¯ä½“å†…ï¼Œä¸åœ¨elseå†…
            
            freq_targets = torch.stack(band_powers, dim=-1)  # [B*R*E, n_freq_bands]
            freq_targets = freq_targets.view(B, R * E, effective_n_freq_bands)
        
        return time_targets, freq_targets


# ä¿ç•™å…¶ä»–è¾…åŠ©å‡½æ•°å’Œç±»ï¼ˆcreate_symmetric_masks, compute_frequency_metricsç­‰ï¼‰
def create_symmetric_masks(batch_size: int, 
                          seq_len: int, 
                          mask_ratio: float = 0.4,
                          mask_strategy: str = 'random',
                          device: torch.device = 'cpu') -> Tuple[torch.Tensor, torch.Tensor]:
    """åˆ›å»ºå¯¹ç§°æ©ç """
    if mask_strategy == 'random':
        mask1 = torch.rand(batch_size, seq_len, device=device) < mask_ratio
        mask2 = torch.rand(batch_size, seq_len, device=device) < mask_ratio
    elif mask_strategy == 'block':
        mask1 = torch.zeros(batch_size, seq_len, device=device, dtype=torch.bool)
        mask2 = torch.zeros(batch_size, seq_len, device=device, dtype=torch.bool)
        
        for b in range(batch_size):
            block_size = max(1, int(seq_len * mask_ratio))
            start_idx = torch.randint(0, seq_len - block_size + 1, (1,)).item()
            mask1[b, start_idx:start_idx + block_size] = True
            
            start_idx = torch.randint(0, seq_len - block_size + 1, (1,)).item()
            mask2[b, start_idx:start_idx + block_size] = True
    else:
        raise ValueError(f"Unknown mask strategy: {mask_strategy}")
    
    return mask1, mask2


def compute_frequency_metrics(original: torch.Tensor, 
                             reconstructed: torch.Tensor) -> Dict[str, float]:
    """è®¡ç®—é¢‘åŸŸæŒ‡æ ‡"""
    # ä½¿ç”¨float32è¿›è¡ŒFFTè®¡ç®—ä»¥é¿å…cuFFTçš„half precisioné™åˆ¶
    with torch.cuda.amp.autocast(enabled=False):
        original_float = original.float()  # ç¡®ä¿è¾“å…¥ä¸º float32
        reconstructed_float = reconstructed.float()  # ç¡®ä¿è¾“å…¥ä¸º float32
        
        # è®¡ç®—åŠŸç‡è°±å¯†åº¦
        orig_fft = torch.fft.rfft(original_float, dim=-1)
        recon_fft = torch.fft.rfft(reconstructed_float, dim=-1)
        
        orig_psd = torch.abs(orig_fft) ** 2
        recon_psd = torch.abs(recon_fft) ** 2
        
        # è®¡ç®—é¢‘åŸŸMSE
        freq_mse = F.mse_loss(recon_psd, orig_psd)
    
    # è®¡ç®—ç›¸ä½ä¸€è‡´æ€§
    orig_phase = torch.angle(orig_fft)
    recon_phase = torch.angle(recon_fft)
    phase_consistency = torch.cos(orig_phase - recon_phase).mean()
    
    return {
        'frequency_mse': freq_mse.item(),
        'phase_consistency': phase_consistency.item(),
    }


def create_frequency_masks(batch_size: int, n_freq_bands: int = 5, mask_ratio: float = 0.3, device: torch.device = 'cpu'):
    """åˆ›å»ºé¢‘åŸŸæ©ç """
    # é˜²æŠ¤æ£€æŸ¥ï¼šç¡®ä¿n_freq_bandsè‡³å°‘ä¸º1
    effective_n_freq_bands = max(1, n_freq_bands)
    n_masked_bands = max(1, int(effective_n_freq_bands * mask_ratio))
    mask = torch.zeros(batch_size, effective_n_freq_bands, device=device, dtype=torch.bool)
    
    for b in range(batch_size):
        masked_indices = torch.randperm(effective_n_freq_bands)[:n_masked_bands]
        mask[b, masked_indices] = True
    
    return mask


def compute_phase_consistency_loss(pred: torch.Tensor, target: torch.Tensor):
    """è®¡ç®—ç›¸ä½ä¸€è‡´æ€§æŸå¤±"""
    # ä½¿ç”¨float32è¿›è¡ŒFFTè®¡ç®—ä»¥é¿å…cuFFTçš„half precisioné™åˆ¶
    with torch.cuda.amp.autocast(enabled=False):
        pred_float = pred.float()  # ç¡®ä¿è¾“å…¥ä¸º float32
        target_float = target.float()  # ç¡®ä¿è¾“å…¥ä¸º float32
        
        pred_fft = torch.fft.rfft(pred_float, dim=-1)
        target_fft = torch.fft.rfft(target_float, dim=-1)
        
        pred_phase = torch.angle(pred_fft)
        target_phase = torch.angle(target_fft)
        
        # è®¡ç®—ç›¸ä½å·®çš„ä½™å¼¦å€¼ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºç›¸ä½è¶Šä¸€è‡´
        phase_consistency = torch.cos(pred_phase - target_phase)
        
        # æŸå¤±ä¸º1å‡å»ç›¸ä½ä¸€è‡´æ€§çš„å¹³å‡å€¼
        loss = 1.0 - phase_consistency.mean()
        
        return loss
    

class DualDomainLoss(nn.Module):
    """åŒåŸŸæŸå¤±å‡½æ•°"""
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.config = config
        self.time_weight = config.time_loss_weight
        self.freq_weight = config.freq_loss_weight
        self.moe_aux_coeff = config.moe_aux_loss_coeff
        
    def forward(self, time_pred1, time_pred2, time_targets, 
               freq_pred1, freq_pred2, freq_targets, 
                moe_aux_loss=None, padding_mask=None, **kwargs):
        
        # åœ¨è®¡ç®—æŸå¤±æ—¶ï¼Œä¸´æ—¶åˆ‡æ¢åˆ° float32 ä»¥ä¿è¯æ•°å€¼ç¨³å®šæ€§
        with torch.cuda.amp.autocast(enabled=False):
            # å°†æ‰€æœ‰è¾“å…¥æ‰‹åŠ¨è½¬æ¢ä¸º float32
            time_pred1_f32 = time_pred1.float()
            time_pred2_f32 = time_pred2.float()
            time_targets_f32 = time_targets.float()
            
            freq_pred1_f32 = freq_pred1.float()
            freq_pred2_f32 = freq_pred2.float()
            freq_targets_f32 = freq_targets.float()

            # åº”ç”¨padding mask
            if padding_mask is not None:
                # padding_mask: [B, R, E] -> [B, R*E]
                mask = ~padding_mask.view(padding_mask.size(0), -1).unsqueeze(-1)  # [B, R*E, 1]
                
                # å¯¹æ—¶åŸŸé¢„æµ‹åº”ç”¨mask
                time_pred1_f32 = time_pred1_f32 * mask
                time_pred2_f32 = time_pred2_f32 * mask
                time_targets_f32 = time_targets_f32 * mask
                
                # å¯¹é¢‘åŸŸé¢„æµ‹åº”ç”¨mask
                freq_mask = mask.expand(-1, -1, freq_pred1_f32.size(-1))  # [B, R*E, n_freq_bands]
                freq_pred1_f32 = freq_pred1_f32 * freq_mask
                freq_pred2_f32 = freq_pred2_f32 * freq_mask
                freq_targets_f32 = freq_targets_f32 * freq_mask

            # æ—¶åŸŸæŸå¤±
            time_loss1 = F.mse_loss(time_pred1_f32, time_targets_f32)
            time_loss2 = F.mse_loss(time_pred2_f32, time_targets_f32)
            time_loss = (time_loss1 + time_loss2) / 2
                
            # é¢‘åŸŸæŸå¤±
            # åœ¨è®¡ç®—MSEä¹‹å‰ï¼Œå¯¹é¢„æµ‹å’Œç›®æ ‡åº”ç”¨log1på˜æ¢ï¼ˆä½¿ç”¨float32ç¡®ä¿æ•°å€¼ç¨³å®šæ€§ï¼‰
            log_freq_pred1 = torch.log1p(F.relu(freq_pred1_f32)) # ä½¿ç”¨ReLUç¡®ä¿è¾“å…¥éè´Ÿ
            log_freq_pred2 = torch.log1p(F.relu(freq_pred2_f32))
            log_freq_targets = torch.log1p(freq_targets_f32) # ç›®æ ‡å·²ç»æ˜¯åŠŸç‡ï¼Œä¿è¯éè´Ÿ

            freq_loss1 = F.mse_loss(log_freq_pred1, log_freq_targets)
            freq_loss2 = F.mse_loss(log_freq_pred2, log_freq_targets)
            freq_loss = (freq_loss1 + freq_loss2) / 2
            
            # ç›¸ä½ä¸€è‡´æ€§æŸå¤±
            phase_loss1 = compute_phase_consistency_loss(time_pred1_f32, time_targets_f32)
            phase_loss2 = compute_phase_consistency_loss(time_pred2_f32, time_targets_f32)
            phase_loss = (phase_loss1 + phase_loss2) / 2
            
            # æ€»æŸå¤±
            total_loss = (self.time_weight * time_loss + 
                         self.freq_weight * freq_loss + 
                         0.1 * phase_loss)
            
            # æ·»åŠ MoEè¾…åŠ©æŸå¤±
            if moe_aux_loss is not None:
                total_loss = total_loss + self.moe_aux_coeff * moe_aux_loss.float()
        
        return {
            'loss': total_loss,
            'time_loss': time_loss.item(),
            'freq_loss': freq_loss.item(),
            'phase_loss': phase_loss.item(),
            'moe_loss': moe_aux_loss.item() if moe_aux_loss is not None else 0.0
        }


class EEGDataAugmentation(nn.Module):
    """EEGæ•°æ®å¢å¼ºï¼ˆä¿æŒä¸å˜ï¼‰"""
    
    def __init__(
        self,
        p_noise: float = 0.5,
        noise_level: float = 0.05,
        p_channel_dropout: float = 0.3,
        dropout_ratio: float = 0.1,
        p_time_shift: float = 0.5,
        max_shift_ratio: float = 0.05
    ):
        super().__init__()
        self.p_noise = p_noise
        self.noise_level = noise_level
        self.p_channel_dropout = p_channel_dropout
        self.dropout_ratio = dropout_ratio
        self.p_time_shift = p_time_shift
        self.max_shift_ratio = max_shift_ratio
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å¯¹è¾“å…¥çš„EEGæ•°æ®è¿›è¡Œéšæœºå¢å¼º
        
        Args:
            x: è¾“å…¥EEGæ•°æ® [B, R, E, T]
               
        Returns:
            å¢å¼ºåçš„EEGæ•°æ®
        """
        if not self.training:
            return x
            
        # éšæœºé€‰æ‹©è¦åº”ç”¨çš„å¢å¼ºæ–¹å¼
        augmentations = []
        
        if torch.rand(1) < self.p_noise:
            augmentations.append(self._add_gaussian_noise)
            
        if torch.rand(1) < self.p_channel_dropout:
            augmentations.append(self._channel_dropout)
            
        if torch.rand(1) < self.p_time_shift:
            augmentations.append(self._random_time_shift)
        
        # ä¾æ¬¡åº”ç”¨é€‰ä¸­çš„å¢å¼º
        for aug_fn in augmentations:
            x = aug_fn(x)
            
        return x

    def _add_gaussian_noise(self, x: torch.Tensor) -> torch.Tensor:
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise_std = self.noise_level * torch.std(x, dim=-1, keepdim=True)
        noise = torch.randn_like(x) * noise_std
        return x + noise
    
    def _channel_dropout(self, x: torch.Tensor) -> torch.Tensor:
        """éšæœºå¤±æ´»é€šé“ï¼ˆè¿™é‡ŒæŒ‡ç”µæï¼‰"""
        B, R, E, T = x.shape
        
        for b in range(B):
            for r in range(R):
                # è®¡ç®—è¦å¤±æ´»çš„ç”µææ•°é‡
                n_dropout = int(E * self.dropout_ratio)
                if n_dropout > 0:
                    # éšæœºé€‰æ‹©è¦å¤±æ´»çš„ç”µæ
                    dropout_indices = torch.randperm(E)[:n_dropout]
                    x[b, r, dropout_indices] = 0
                    
        return x
    
    def _random_time_shift(self, x: torch.Tensor) -> torch.Tensor:
        """éšæœºæ—¶é—´åç§»"""
        B, R, E, T = x.shape
        max_shift = int(T * self.max_shift_ratio)
        
        if max_shift > 0:
            for b in range(B):
                shift = torch.randint(-max_shift, max_shift + 1, (1,)).item()
                if shift != 0:
                    x[b] = torch.roll(x[b], shift, dims=-1)
                    
        return x


def count_model_parameters(model, config: ModelConfig = None, verbose: bool = True):
    """
    è®¡ç®—æ¨¡å‹å‚æ•°é‡çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        model: è¦ç»Ÿè®¡çš„æ¨¡å‹å®ä¾‹
        config: æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼Œç”¨äºæ˜¾ç¤ºé…ç½®ä¿¡æ¯ï¼‰
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
    Returns:
        Dict: åŒ…å«å„ç§å‚æ•°ç»Ÿè®¡çš„å­—å…¸
    """
    from torch.nn.parallel import DistributedDataParallel as DDP
    
    # è·å–åŸå§‹æ¨¡å‹ï¼ˆå»é™¤DDPåŒ…è£…ï¼‰
    raw_model = model.module if isinstance(model, DDP) else model
    
    # åŸºæœ¬å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in raw_model.parameters())
    trainable_params = sum(p.numel() for p in raw_model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    # æŒ‰ä¸»è¦ç»„ä»¶ç»Ÿè®¡å‚æ•°é‡
    component_stats = {}
    for name, module in raw_model.named_children():
        if hasattr(module, 'parameters'):
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                component_stats[name] = params
    
    # æŒ‰æ¨¡å—ç±»å‹ç»Ÿè®¡å‚æ•°é‡
    module_type_stats = {}
    for name, module in raw_model.named_modules():
        module_type = type(module).__name__
        if module_type not in module_type_stats:
            module_type_stats[module_type] = {'count': 0, 'params': 0}
        
        # åªç»Ÿè®¡ç›´æ¥å±äºè¯¥æ¨¡å—çš„å‚æ•°ï¼Œé¿å…é‡å¤è®¡ç®—
        direct_params = sum(p.numel() for p in module.parameters(recurse=False))
        if direct_params > 0:
            module_type_stats[module_type]['count'] += 1
            module_type_stats[module_type]['params'] += direct_params
    
    # ç§»é™¤å‚æ•°ä¸º0çš„æ¨¡å—ç±»å‹
    module_type_stats = {k: v for k, v in module_type_stats.items() if v['params'] > 0}
    
    # å†…å­˜å ç”¨ä¼°ç®—ï¼ˆMBï¼‰
    fp32_memory = total_params * 4 / 1024 / 1024  # 4 bytes per parameter
    fp16_memory = total_params * 2 / 1024 / 1024  # 2 bytes per parameter
    
    # æ¢¯åº¦å†…å­˜å ç”¨ï¼ˆè®­ç»ƒæ—¶ï¼‰
    gradient_memory = trainable_params * 4 / 1024 / 1024  # FP32 gradients
    
    # Adamä¼˜åŒ–å™¨çŠ¶æ€å†…å­˜å ç”¨ï¼ˆmå’ŒvçŠ¶æ€ï¼‰
    adam_memory = trainable_params * 8 / 1024 / 1024  # 2 states * 4 bytes each
    
    # æ€»è®­ç»ƒå†…å­˜ä¼°ç®—ï¼ˆæ¨¡å‹ + æ¢¯åº¦ + ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰
    total_training_memory_fp32 = fp32_memory + gradient_memory + adam_memory
    total_training_memory_fp16 = fp16_memory + gradient_memory + adam_memory
    
    # æ„å»ºç»“æœå­—å…¸
    stats = {
        'basic': {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'frozen_params': frozen_params,
            'trainable_ratio': trainable_params / total_params * 100 if total_params > 0 else 0
        },
        'memory': {
            'model_fp32_mb': fp32_memory,
            'model_fp16_mb': fp16_memory,
            'gradient_mb': gradient_memory,
            'adam_states_mb': adam_memory,
            'total_training_fp32_mb': total_training_memory_fp32,
            'total_training_fp16_mb': total_training_memory_fp16
        },
        'components': component_stats,
        'module_types': module_type_stats,
        'model_class': type(raw_model).__name__
    }
    
    if verbose:
        print("\n" + "="*80)
        print(f"{'æ¨¡å‹å‚æ•°ç»Ÿè®¡æŠ¥å‘Š':^80}")
        print("="*80)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“Š {'åŸºæœ¬å‚æ•°ç»Ÿè®¡':^70}")
        print("-" * 75)
        print(f"{'æ¨¡å‹ç±»å‹:':<20} {stats['model_class']}")
        print(f"{'æ€»å‚æ•°é‡:':<20} {total_params:,} ({total_params/1e6:.2f}M)")
        print(f"{'å¯è®­ç»ƒå‚æ•°:':<20} {trainable_params:,} ({trainable_params/1e6:.2f}M)")
        print(f"{'å†»ç»“å‚æ•°:':<20} {frozen_params:,} ({frozen_params/1e6:.2f}M)")
        print(f"{'å¯è®­ç»ƒæ¯”ä¾‹:':<20} {stats['basic']['trainable_ratio']:.1f}%")
        
        # å†…å­˜å ç”¨
        print(f"\nğŸ’¾ {'å†…å­˜å ç”¨ä¼°ç®—':^70}")
        print("-" * 75)
        print(f"{'æ¨¡å‹å‚æ•°(FP32):':<20} {fp32_memory:.1f} MB")
        print(f"{'æ¨¡å‹å‚æ•°(FP16):':<20} {fp16_memory:.1f} MB")
        print(f"{'æ¢¯åº¦(FP32):':<20} {gradient_memory:.1f} MB")
        print(f"{'AdamçŠ¶æ€:':<20} {adam_memory:.1f} MB")
        print(f"{'è®­ç»ƒæ€»å†…å­˜(FP32):':<20} {total_training_memory_fp32:.1f} MB ({total_training_memory_fp32/1024:.2f} GB)")
        print(f"{'è®­ç»ƒæ€»å†…å­˜(FP16):':<20} {total_training_memory_fp16:.1f} MB ({total_training_memory_fp16/1024:.2f} GB)")
        
        # ä¸»è¦ç»„ä»¶åˆ†å¸ƒ
        if component_stats:
            print(f"\nğŸ—ï¸  {'ä¸»è¦ç»„ä»¶å‚æ•°åˆ†å¸ƒ':^70}")
            print("-" * 75)
            sorted_components = sorted(component_stats.items(), key=lambda x: x[1], reverse=True)
            for name, params in sorted_components:
                percentage = params / total_params * 100
                print(f"{name:<30} {params:>15,} ({percentage:>5.1f}%)")
        
        # æ¨¡å—ç±»å‹ç»Ÿè®¡
        if module_type_stats:
            print(f"\nğŸ”§ {'æ¨¡å—ç±»å‹ç»Ÿè®¡':^70}")
            print("-" * 75)
            print(f"{'æ¨¡å—ç±»å‹':<25} {'å®ä¾‹æ•°':<8} {'å‚æ•°é‡':<15} {'å æ¯”'}")
            print("-" * 75)
            sorted_modules = sorted(module_type_stats.items(), key=lambda x: x[1]['params'], reverse=True)
            for module_type, info in sorted_modules:
                percentage = info['params'] / total_params * 100
                print(f"{module_type:<25} {info['count']:<8} {info['params']:>12,} ({percentage:>5.1f}%)")
        
        # é…ç½®ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
        if config:
            print(f"\nâš™ï¸  {'æ¨¡å‹é…ç½®ä¿¡æ¯':^70}")
            print("-" * 75)
            print(f"{'åµŒå…¥ç»´åº¦:':<20} {config.embed_dim}")
            print(f"{'æ³¨æ„åŠ›å¤´æ•°:':<20} {config.num_heads}")
            print(f"{'Transformerå±‚æ•°:':<20} {config.depth}")
            print(f"{'MLPæ¯”ä¾‹:':<20} {config.mlp_ratio}")
            if hasattr(config, 'use_moe') and config.use_moe:
                print(f"{'ä½¿ç”¨MoE:':<20} Yes (ä¸“å®¶æ•°: {config.num_experts}, Top-K: {config.top_k_experts})")
            else:
                print(f"{'ä½¿ç”¨MoE:':<20} No")
            print(f"{'åºåˆ—é•¿åº¦:':<20} {config.num_regions} Ã— {config.max_electrodes_per_region} = {config.num_regions * config.max_electrodes_per_region}")
            print(f"{'è¾“å…¥ç»´åº¦:':<20} [{config.num_regions}, {config.max_electrodes_per_region}, {config.sequence_length}]")

    
    return stats


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºé…ç½®å’Œæ¨¡å‹
    config = ModelConfig()
    model = DualDomainTransformerMEM(config)
    
    # è®¡ç®—å‚æ•°é‡
    stats = count_model_parameters(model, config, verbose=True)

