# -*- coding: utf-8 -*-

import os
import torch
# å¯ç”¨ TensorFloat32 æ ¸å¿ƒä»¥æå‡æ€§èƒ½
#torch.set_float32_matmul_precision('high') 
import torch.nn as nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, TensorDataset, random_split
from torch.utils.data.distributed import DistributedSampler
from torch.cuda.amp import autocast, GradScaler
from typing import Dict, Tuple, Optional, List
import time
import warnings
import gc
import math

# å±è”½æ‰€æœ‰torchvisionç›¸å…³è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="torchvision")
# å±è”½å­¦ä¹ ç‡è°ƒåº¦å™¨è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="torch.optim.lr_scheduler")
# å±è”½å…¶ä»–å¸¸è§è­¦å‘Š
warnings.filterwarnings("ignore", message=".*skipping the first value of the learning rate schedule.*")
warnings.filterwarnings("ignore", message=".*Failed to load image Python extension.*")

# å¯¼å…¥æ¨¡å‹å’Œæ•°æ®åŠ è½½å™¨
from model_slurm_1 import (DualDomainTransformerMEM, ModelConfig, 
                  create_symmetric_masks, create_frequency_masks, 
                  compute_frequency_metrics, compute_phase_consistency_loss,
                  DualDomainLoss, EEGDataAugmentation)
from load_slurm_1 import EEGBrainRegionDataset, create_data_loader

# ========================= DDP ç›¸å…³å‡½æ•° =========================
def setup_ddp():
    """åˆå§‹åŒ–DDPç¯å¢ƒï¼Œä½¿ç”¨Slurmæä¾›çš„ç¯å¢ƒå˜é‡"""
    # ä»Slurmç¯å¢ƒå˜é‡è·å–åˆ†å¸ƒå¼ä¿¡æ¯
    rank = int(os.environ['SLURM_PROCID'])
    local_rank = int(os.environ['SLURM_LOCALID'])
    world_size = int(os.environ['SLURM_NTASKS'])
    
    # è·å–masterèŠ‚ç‚¹ä¿¡æ¯
    master_addr = os.environ.get('MASTER_ADDR', 'localhost')
    master_port = os.environ.get('MASTER_PORT', '12355')
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä»¥é˜²æœªè®¾ç½®ï¼‰
    os.environ['MASTER_ADDR'] = master_addr
    os.environ['MASTER_PORT'] = master_port
    
    # ç»‘å®šGPU
    torch.cuda.set_device(local_rank)
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„
    dist.init_process_group(
        backend='nccl',
        init_method=f'tcp://{master_addr}:{master_port}',
        world_size=world_size,
        rank=rank
    )
    
    # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
    dist.barrier()
    
    return rank, local_rank, world_size

def cleanup_ddp():
    """æ¸…ç†DDPç¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()

def is_main_process():
    """åˆ¤æ–­æ˜¯å¦ä¸ºä¸»è¿›ç¨‹"""
    return not dist.is_initialized() or dist.get_rank() == 0

def print_rank_0(message, end='\n'):
    """åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰“å°æ¶ˆæ¯"""
    if is_main_process():
        print(message, end=end)

def reduce_tensor(tensor: torch.Tensor) -> torch.Tensor:
    """åœ¨æ‰€æœ‰è¿›ç¨‹é—´èšåˆå¼ é‡å¹¶è¿”å›å¹³å‡å€¼"""
    if not dist.is_initialized():
        return tensor
    
    # ç¡®ä¿tensoråœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
    if not tensor.is_cuda:
        tensor = tensor.cuda()
    
    # å…‹éš†tensorä»¥é¿å…ä¿®æ”¹åŸå§‹å€¼
    reduced_tensor = tensor.clone()
    
    # æ‰§è¡Œall_reduceæ“ä½œ
    dist.all_reduce(reduced_tensor, op=dist.ReduceOp.AVG)
    
    return reduced_tensor

def aggregate_metrics(metrics: Dict[str, float]) -> Dict[str, float]:
    """èšåˆæ‰€æœ‰è¿›ç¨‹çš„æŒ‡æ ‡"""
    if not dist.is_initialized():
        return metrics
    
    aggregated_metrics = {}
    for key, value in metrics.items():
        if isinstance(value, (int, float)):
            # å°†æ ‡é‡è½¬æ¢ä¸ºtensorè¿›è¡Œèšåˆ
            tensor_value = torch.tensor(value, dtype=torch.float32, device=torch.cuda.current_device())
            reduced_value = reduce_tensor(tensor_value)
            aggregated_metrics[key] = reduced_value.item()
        else:
            aggregated_metrics[key] = value
    
    return aggregated_metrics

# ========================= DualDomainTrainer ç±» =========================

class DualDomainTrainer:
    """å°è£…æ—¶åŸŸå’Œé¢‘åŸŸå¤šä»»åŠ¡å­¦ä¹ è®­ç»ƒé€»è¾‘ - DDPç‰ˆæœ¬"""
    def __init__(self, model: nn.Module, optimizer: torch.optim.Optimizer, config: ModelConfig, device: torch.device, rank: int = 0):
        self.config = config
        self.device = device
        self.rank = rank
        self.is_ddp = dist.is_initialized()
        
        # æ¥å—å¤–éƒ¨ä¼ å…¥çš„æ¨¡å‹å’Œä¼˜åŒ–å™¨
        self.model = model
        self.optimizer = optimizer
        
        # åœ¨DDPç¯å¢ƒä¸­ï¼Œæœ‰æ•ˆæ‰¹æ¬¡å¤§å°æ˜¯æ‰€æœ‰è¿›ç¨‹çš„æ€»å’Œ
        if self.is_ddp:
            self.effective_batch_size = config.batch_size * dist.get_world_size()
            print_rank_0(f"DDPè®­ç»ƒï¼Œä¸–ç•Œå¤§å°: {dist.get_world_size()}, æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {self.effective_batch_size}")
        else:
            self.effective_batch_size = config.batch_size
            print_rank_0(f"å•GPUè®­ç»ƒï¼Œæ‰¹æ¬¡å¤§å°: {self.effective_batch_size}")
        
        # åˆå§‹åŒ–æ•°æ®å¢å¼ºæ¨¡å—
        self.data_augmentation = EEGDataAugmentation(
            p_noise=0.5,                # 50%æ¦‚ç‡åº”ç”¨å™ªå£°
            noise_level=0.05,           # å™ªå£°å¼ºåº¦ä¸ºä¿¡å·æ ‡å‡†å·®çš„5%
            p_channel_dropout=0.3,      # 30%æ¦‚ç‡åº”ç”¨é€šé“å¤±æ´»
            dropout_ratio=0.1,          # éšæœºå¤±æ´»10%çš„ç”µæ
            p_time_shift=0.4,           # 40%æ¦‚ç‡åº”ç”¨æ—¶é—´åç§»
            max_shift_ratio=0.05        # æœ€å¤§åç§»ä¸ºæ—¶é—´è½´5%
        ).to(device)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨å°†åœ¨è®¾ç½®è®­ç»ƒæ•°æ®åŠ è½½å™¨ååˆå§‹åŒ–
        self.lr_scheduler = None
        self.steps_per_epoch = None  # å°†åœ¨setup_trainingä¸­è®¾ç½®
        
        # å¤šä»»åŠ¡æŸå¤±å‡½æ•° - æ”¯æŒMoEè¾…åŠ©æŸå¤±
        self.loss_fn = DualDomainLoss(config)
        self.loss_scale = 0.1  # æ·»åŠ æŸå¤±ç¼©æ”¾å› å­
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.use_amp = config.use_amp
        self.scaler = GradScaler(init_scale=2**16) if config.use_amp else None  # é™ä½åˆå§‹ç¼©æ”¾å› å­
        
        # è®­ç»ƒçŠ¶æ€
        self.global_step = 0
        
        # æ—¶é—´ç®¡ç† - ç»Ÿä¸€åˆå§‹åŒ–
        self.training_start_time = None  # å°†åœ¨trainæ–¹æ³•å¼€å§‹æ—¶è®¾ç½®
        self.last_periodic_save_time = None  # å‘¨æœŸæ€§ä¿å­˜è®¡æ—¶å™¨
        
        # æ¢¯åº¦ç´¯ç§¯æ­¥æ•° - åŠ¨æ€è®¡ç®—
        target_global_batch_size = 128  # ç›®æ ‡å…¨å±€æ‰¹æ¬¡å¤§å°
        current_global_batch_size = config.batch_size * (dist.get_world_size() if self.is_ddp else 1)
        self.gradient_accumulation_steps = max(1, target_global_batch_size // current_global_batch_size)
        
        print_rank_0(f"åŠ¨æ€æ¢¯åº¦ç´¯ç§¯è®¾ç½®:")
        print_rank_0(f"  ç›®æ ‡å…¨å±€æ‰¹æ¬¡å¤§å°: {target_global_batch_size}")
        print_rank_0(f"  å½“å‰å…¨å±€æ‰¹æ¬¡å¤§å°: {current_global_batch_size}")
        print_rank_0(f"  æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {self.gradient_accumulation_steps}")
        print_rank_0(f"  å®é™…æœ‰æ•ˆå…¨å±€æ‰¹æ¬¡å¤§å°: {current_global_batch_size * self.gradient_accumulation_steps}")
        
        # è®¡ç®—å¹¶å­˜å‚¨æ¨¡å‹å‚æ•°ç»Ÿè®¡ä¿¡æ¯
        self.param_stats = self._calculate_model_parameters()
        
        # è®­ç»ƒæŒ‡æ ‡
        self.metrics = {
            'train_loss': [],
            'time_loss': [],
            'freq_loss': [],
            'phase_loss': []
        }
        
        # æœ€ä½³æŸå¤±è·Ÿè¸ª
        self.best_loss = float('inf')
        
        # åˆ›å»ºæœ¬æ¬¡è¿è¡Œçš„æ–‡ä»¶å¤¹
        run_name = time.strftime('%Y%m%d_%H%M%S')
        self.run_checkpoint_dir = f"checkpoint/{run_name}"
        os.makedirs(self.run_checkpoint_dir, exist_ok=True)
        
        # æ—¥å¿—è®°å½•å™¨
        self.tensorboard_writer = None
        self.log_dir = None
    
    def _calculate_model_parameters(self):
        """è®¡ç®—æ¨¡å‹å‚æ•°é‡çš„è¯¦ç»†ç»Ÿè®¡"""
        # è·å–åŸå§‹æ¨¡å‹ï¼ˆå»é™¤DDPåŒ…è£…ï¼‰
        raw_model = self.model.module if isinstance(self.model, DDP) else self.model
        
        total_params = sum(p.numel() for p in raw_model.parameters())
        trainable_params = sum(p.numel() for p in raw_model.parameters() if p.requires_grad)
        frozen_params = total_params - trainable_params
        
        # æŒ‰ä¸»è¦ç»„ä»¶ç»Ÿè®¡å‚æ•°é‡
        component_params = {}
        
        # ç»Ÿè®¡å„ä¸ªä¸»è¦ç»„ä»¶çš„å‚æ•°é‡
        for name, module in raw_model.named_children():
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                component_params[name] = params
        
        # æŒ‰æ¨¡å—ç±»å‹ç»Ÿè®¡
        module_type_params = {}
        for name, module in raw_model.named_modules():
            module_type = type(module).__name__
            if module_type not in module_type_params:
                module_type_params[module_type] = 0
            # åªç»Ÿè®¡ç›´æ¥å±äºè¯¥æ¨¡å—çš„å‚æ•°ï¼Œé¿å…é‡å¤è®¡ç®—
            direct_params = sum(p.numel() for p in module.parameters(recurse=False))
            module_type_params[module_type] += direct_params
        
        # ç§»é™¤å‚æ•°ä¸º0çš„æ¨¡å—ç±»å‹
        module_type_params = {k: v for k, v in module_type_params.items() if v > 0}
        
        return {
            'total': total_params,
            'trainable': trainable_params,
            'frozen': frozen_params,
            'components': component_params,
            'module_types': module_type_params,
            'memory_fp32_mb': total_params * 4 / 1024 / 1024,
            'memory_fp16_mb': total_params * 2 / 1024 / 1024
        }
        
    def setup_training(self, train_loader, num_epochs=None):
        """è®¾ç½®è®­ç»ƒæ•°æ®åŠ è½½å™¨å’Œç›¸å…³å‚æ•°"""
        self.steps_per_epoch = len(train_loader)
        self.num_epochs = num_epochs or self.config.warmup_epochs
        
        # ç°åœ¨å¯ä»¥æ­£ç¡®åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(
            self.optimizer,
            max_lr=self.config.lr,
            epochs=self.num_epochs,  # ä½¿ç”¨å®é™…çš„è®­ç»ƒepochs
            steps_per_epoch=self.steps_per_epoch,  # ä½¿ç”¨å®é™…çš„æ¯ä¸ªepochçš„æ­¥æ•°
            pct_start=0.5,  # å¢åŠ é¢„çƒ­é˜¶æ®µæ¯”ä¾‹
            anneal_strategy='cos',
            div_factor=50.0,  # å¢åŠ åˆå§‹å­¦ä¹ ç‡é™ä½ç¨‹åº¦
            final_div_factor=2000.0  # å¢åŠ æœ€ç»ˆå­¦ä¹ ç‡é™ä½ç¨‹åº¦
        )
        
        print_rank_0(f"å­¦ä¹ ç‡è°ƒåº¦å™¨å·²åˆå§‹åŒ–ï¼Œæ€»è®­ç»ƒepochs: {self.num_epochs}, æ¯ä¸ªepochçš„æ­¥æ•°: {self.steps_per_epoch}")
        print_rank_0(f"æ€»è®­ç»ƒæ­¥æ•°: {self.num_epochs * self.steps_per_epoch}")
    
    def setup_logging(self, log_dir='./logs', record_graph=False):
        """è®¾ç½®TensorBoardæ—¥å¿—è®°å½•
        
        Args:
            log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
            record_graph: æ˜¯å¦è®°å½•æ¨¡å‹è®¡ç®—å›¾ï¼Œè®¾ç½®ä¸ºFalseå¯é¿å…TracerWarningå’Œç»´åº¦ä¸åŒ¹é…é—®é¢˜
        """
        try:
            from torch.utils.tensorboard import SummaryWriter
            import os
            
            # åˆ›å»ºæ—¥å¿—ç›®å½•
            os.makedirs(log_dir, exist_ok=True)
            self.log_dir = log_dir
            
            # åˆ›å»ºæ›´å…·æè¿°æ€§çš„è¿è¡Œåç§°
            run_name = (f"{time.strftime('%Y%m%d-%H%M%S')}_"
                       f"emb{self.config.embed_dim}_"
                       f"depth{self.config.depth}_"
                       f"bs{self.config.batch_size}")
            
            # åˆ›å»ºæ—¥å¿—å†™å…¥å™¨
            log_path = f"{log_dir}/{run_name}"
            self.tensorboard_writer = SummaryWriter(log_path)
            
            print_rank_0(f"TensorBoardæ—¥å¿—å°†ä¿å­˜åˆ° {log_path}")
            
            # è®°å½•æ¨¡å‹å›¾ï¼ˆå¯é€‰ï¼‰
            if record_graph:
                try:
                    # åˆ›å»ºä¸æ¨¡å‹æœŸæœ›å½¢çŠ¶åŒ¹é…çš„dummy_input
                    # é¦–å…ˆè·å–æ¨¡å‹æœŸæœ›çš„è¾“å…¥å½¢çŠ¶
                    batch_size = 2  # ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡å¤§å°é¿å…å†…å­˜é—®é¢˜
                    in_channels = self.config.in_chans
                    
                    # ä½¿ç”¨æ¨¡å‹ä¸­å®é™…çš„ç”µææ•°é‡ä½œä¸ºHç»´åº¦
                    if hasattr(self.config, 'electrode_names') and self.config.electrode_names:
                        height = len(self.config.electrode_names)
                    else:
                        height = 22  # é»˜è®¤ç”µææ•°é‡
                        
                    # ä½¿ç”¨è¾ƒå°çš„æ—¶é—´ç»´åº¦ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
                    width = 160
                    
                    print_rank_0(f"åˆ›å»ºç¤ºä¾‹è¾“å…¥ï¼Œå½¢çŠ¶: [{batch_size}, {in_channels}, {height}, {width}]")
                    
                    # åˆ›å»ºdummy_input
                    dummy_input = torch.randn(batch_size, in_channels, height, width, device=self.device)
                    
                    # è·å–åŸå§‹æ¨¡å‹ç”¨äºå›¾è®°å½•
                    raw_model = self.model.module if isinstance(self.model, DDP) else self.model
                    
                    # é¦–å…ˆéªŒè¯è¾“å…¥å½¢çŠ¶æ˜¯å¦æ­£ç¡®
                    with torch.no_grad():
                        try:
                            time_features, freq_features, raw_features = raw_model.dual_proj(dummy_input)
                            print_rank_0(f"è¾“å…¥éªŒè¯æˆåŠŸ: æ—¶åŸŸç‰¹å¾: {time_features.shape}, é¢‘åŸŸç‰¹å¾: {freq_features.shape}, åŸå§‹ä¿¡å·ç‰¹å¾: {raw_features.shape}")
                            
                            # å†å°è¯•å®Œæ•´çš„å‰å‘ä¼ æ’­
                            _ = raw_model(dummy_input)
                            print_rank_0("å®Œæ•´å‰å‘ä¼ æ’­éªŒè¯æˆåŠŸï¼Œè®°å½•æ¨¡å‹å›¾...")
                            
                            # è®°å½•æ¨¡å‹å›¾ï¼ˆä½¿ç”¨åŸå§‹æ¨¡å‹ï¼‰
                            self.tensorboard_writer.add_graph(raw_model, dummy_input)
                            print_rank_0("æ¨¡å‹å›¾å·²æˆåŠŸè®°å½•åˆ°TensorBoard")
                        except Exception as e:
                            print_rank_0(f"è¾“å…¥éªŒè¯å¤±è´¥: {str(e)}")
                            print_rank_0("å°è¯•ä¸è®°å½•æ¨¡å‹å›¾è€Œç»§ç»­è®­ç»ƒ...")
                except Exception as e:
                    print_rank_0(f"æ— æ³•è®°å½•æ¨¡å‹å›¾: {str(e)}")
                    print_rank_0("è·³è¿‡æ¨¡å‹å›¾è®°å½•ï¼Œç»§ç»­è®­ç»ƒ...")
            else:
                print_rank_0("å·²ç¦ç”¨æ¨¡å‹å›¾è®°å½•ä»¥é¿å…TracerWarningå’Œç»´åº¦ä¸åŒ¹é…é—®é¢˜")
            
            # è®°å½•è¶…å‚æ•°å’Œæ¨¡å‹å‚æ•°ç»Ÿè®¡
            try:
                hparams = {k: v for k, v in self.config.__dict__.items() 
                          if not k.startswith('_') and isinstance(v, (int, float, str, bool))}
                # æ·»åŠ æ¨¡å‹å‚æ•°ç»Ÿè®¡åˆ°è¶…å‚æ•°
                hparams.update({
                    'model/total_params': self.param_stats['total'],
                    'model/trainable_params': self.param_stats['trainable'],
                    'model/memory_fp32_mb': self.param_stats['memory_fp32_mb'],
                    'model/memory_fp16_mb': self.param_stats['memory_fp16_mb']
                })
                metric_dict = {'hparam/val_loss': 0}  # ä½¿ç”¨æ›´æœ‰æ„ä¹‰çš„æŒ‡æ ‡åç§°
                self.tensorboard_writer.add_hparams(hparams, metric_dict)
                
                # è®°å½•æ¨¡å‹å‚æ•°ç»Ÿè®¡ä¿¡æ¯
                self.tensorboard_writer.add_scalar('model/total_parameters', self.param_stats['total'], 0)
                self.tensorboard_writer.add_scalar('model/trainable_parameters', self.param_stats['trainable'], 0)
                self.tensorboard_writer.add_scalar('model/memory_fp32_mb', self.param_stats['memory_fp32_mb'], 0)
                self.tensorboard_writer.add_scalar('model/memory_fp16_mb', self.param_stats['memory_fp16_mb'], 0)
                
                print_rank_0("è¶…å‚æ•°å’Œæ¨¡å‹å‚æ•°ç»Ÿè®¡å·²è®°å½•åˆ°TensorBoard")
            except Exception as e:
                print_rank_0(f"è®°å½•è¶…å‚æ•°å¤±è´¥: {str(e)}")
            
            return True
        except ImportError:
            print_rank_0("è­¦å‘Š: æœªæ‰¾åˆ°TensorBoardï¼Œå°†ä¸ä¼šè®°å½•è®­ç»ƒæ—¥å¿—")
            return False
        except Exception as e:
            print_rank_0(f"è®¾ç½®TensorBoardæ—¥å¿—å¤±è´¥: {str(e)}")
            return False
    
    def log_metrics(self, metrics, step, prefix='train'):
        """è®°å½•æŒ‡æ ‡åˆ°TensorBoard"""
        if self.tensorboard_writer is None:
            return
        
        # è®°å½•æ ‡é‡å€¼
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                self.tensorboard_writer.add_scalar(f"{prefix}/{key}", value, step)
            elif isinstance(value, dict):
                # å¤„ç†åµŒå¥—å­—å…¸
                for nested_key, nested_value in value.items():
                    if isinstance(nested_value, (int, float)):
                        self.tensorboard_writer.add_scalar(
                            f"{prefix}/{key}/{nested_key}",
                            nested_value,
                            step
                        )
        
        # è®°å½•å­¦ä¹ ç‡
        if hasattr(self, 'optimizer') and self.optimizer is not None:
            current_lr = self.optimizer.param_groups[0]['lr']
            self.tensorboard_writer.add_scalar(f"{prefix}/learning_rate", current_lr, step)
    
    def _validate_input_format(self, x: torch.Tensor, padding_mask: torch.Tensor) -> None:
        """éªŒè¯è¾“å…¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
        
        Args:
            x: è¾“å…¥æ•°æ®å¼ é‡ [B, R, E, T]
            padding_mask: å¡«å……æ©ç  [B, R, E]
        """
        # éªŒè¯è¾“å…¥æ•°æ®ç»´åº¦
        if x.dim() != 4:
            raise ValueError(f"æœŸæœ›4Dè¾“å…¥å¼ é‡ [B, R, E, T]ï¼Œå¾—åˆ° {x.dim()}D: {x.shape}")
        
        # éªŒè¯padding maskç»´åº¦
        if padding_mask.dim() != 3:
            raise ValueError(f"æœŸæœ›3Då¡«å……æ©ç  [B, R, E]ï¼Œå¾—åˆ° {padding_mask.dim()}D: {padding_mask.shape}")
        
        # éªŒè¯ç»´åº¦åŒ¹é…
        B, R, E, T = x.shape
        if padding_mask.shape != (B, R, E):
            raise ValueError(f"æ•°æ®å½¢çŠ¶ {x.shape} ä¸æ©ç å½¢çŠ¶ {padding_mask.shape} ä¸åŒ¹é…")
        
        # åªåœ¨ç¬¬ä¸€æ­¥æ‰“å°ç»´åº¦ä¿¡æ¯
        if self.global_step == 0:
            print_rank_0(f"\n=== è¾“å…¥æ•°æ®æ ¼å¼éªŒè¯ ===")
            print_rank_0(f"æ•°æ®å½¢çŠ¶: {x.shape} [æ‰¹æ¬¡, è„‘åŒº, ç”µæ, æ—¶é—´]")
            print_rank_0(f"æ©ç å½¢çŠ¶: {padding_mask.shape} [æ‰¹æ¬¡, è„‘åŒº, ç”µæ]")
            print_rank_0(f"è„‘åŒºæ•°é‡: {R}")
            print_rank_0(f"æ¯ä¸ªè„‘åŒºæœ€å¤§ç”µææ•°: {E}")
            print_rank_0(f"æ—¶é—´åºåˆ—é•¿åº¦: {T}")
            
            # ç»Ÿè®¡çœŸå®ç”µææ•°é‡
            for r in range(R):
                real_electrodes = (~padding_mask[0, r]).sum().item()
                print_rank_0(f"  è„‘åŒº {r}: {real_electrodes} ä¸ªçœŸå®ç”µæ")
            print_rank_0("=" * 30)
    
    def _run_one_step(self, x: torch.Tensor, padding_mask: torch.Tensor) -> Dict[str, torch.Tensor]:
        """æ‰§è¡Œæ¨¡å‹å‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—çš„æ ¸å¿ƒæµç¨‹
        
        å‚æ•°:
            x: è¾“å…¥æ•°æ® [B, R, E, T]
            padding_mask: å¡«å……é®ç½© [B, R, E]ï¼ŒTrueè¡¨ç¤ºå¡«å……ä½ç½®
            
        è¿”å›:
            ç»“æœå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹é”®:
            - time_pred1, time_pred2: æ—¶åŸŸé¢„æµ‹
            - freq_pred1, freq_pred2: é¢‘åŸŸé¢„æµ‹
            - time_targets, freq_targets: ç›®æ ‡ç‰¹å¾
            - loss_dict: æŸå¤±å­—å…¸
            - loss: æ€»æŸå¤±(å·²ä¹˜ä»¥loss_scale)
            - region_losses: è„‘åŒºçº§åˆ«æŸå¤±å­—å…¸
            - moe_aux_loss: MoEè¾…åŠ©æŸå¤± (å¦‚æœä½¿ç”¨MoE)
        """
        # è·å–åŸå§‹æ¨¡å‹ï¼ˆå»é™¤DDPåŒ…è£…ï¼‰
        raw_model = self.model.module if isinstance(self.model, DDP) else self.model
        
        # éªŒè¯è¾“å…¥æ ¼å¼
        self._validate_input_format(x, padding_mask)
        
        # æ·»åŠ GPUåŒæ­¥ç‚¹ï¼Œç¡®ä¿æ‰€æœ‰GPUæ“ä½œå®Œæˆ
        torch.cuda.synchronize()
        
        # è·å–æ•°æ®ç»´åº¦
        B, R, E, T = x.shape
        seq_len = R * E  # åºåˆ—é•¿åº¦ç°åœ¨æ˜¯è„‘åŒºæ•°Ã—ç”µææ•°
        
        # åªåœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ‰“å°ç»´åº¦ä¿¡æ¯ï¼ˆå·²åœ¨_validate_input_formatä¸­å¤„ç†ï¼‰
        
        # åˆ›å»ºæ—¶åŸŸæ©ç  - ç°åœ¨åŸºäºåºåˆ—é•¿åº¦R*E
        time_mask1, _ = create_symmetric_masks(
            B, seq_len, 
            mask_ratio=self.config.mask_ratio,
            mask_strategy=self.config.mask_strategy,
            device=self.device
        )
        
        # åˆ›å»ºé¢‘åŸŸæ©ç 
        freq_mask1 = create_frequency_masks(
            B, self.config.n_freq_bands,
            mask_ratio=self.config.freq_mask_ratio,
            device=self.device
        )
        
        # å‰å‘è®¡ç®— - è·å–æ—¶åŸŸå’Œé¢‘åŸŸé¢„æµ‹ï¼Œä»¥åŠMoEè¾…åŠ©æŸå¤±
        time_pred1, time_pred2, freq_pred1, freq_pred2, moe_aux_loss = self.model(
            x, time_mask=time_mask1, freq_mask=freq_mask1, padding_mask=padding_mask
        )
        
        # ç›®æ ‡ç‰¹å¾
        time_targets, freq_targets = raw_model.get_targets(x, padding_mask=padding_mask)
        
        # è®¡ç®—å¤šä»»åŠ¡æŸå¤±ï¼ŒåŒ…æ‹¬MoEè¾…åŠ©æŸå¤±
        loss_dict = self.loss_fn(
            time_pred1, time_pred2, time_targets,
            freq_pred1, freq_pred2, freq_targets,
            moe_aux_loss=moe_aux_loss,
            padding_mask=padding_mask
        )
        
        # æ€»æŸå¤± - ç¡®ä¿åœ¨å¤šGPUç¯å¢ƒä¸‹æŸå¤±æ˜¯æ ‡é‡
        loss = loss_dict['loss']
        if loss.dim() > 0:  # å¦‚æœæŸå¤±ä¸æ˜¯æ ‡é‡ï¼ˆå¤šGPUæƒ…å†µï¼‰
            loss = loss.mean()  # å–å¹³å‡å€¼
        loss = loss * self.loss_scale
        
        # è®¡ç®—è„‘åŒºçº§åˆ«çš„æŸå¤±
        region_losses = self._compute_region_losses(time_pred1, time_targets, freq_pred1, freq_targets)
        
        # è¿”å›æ‰€æœ‰ç»“æœ
        return {
            'time_pred1': time_pred1,
            'time_pred2': time_pred2,
            'freq_pred1': freq_pred1,
            'freq_pred2': freq_pred2,
            'time_targets': time_targets,
            'freq_targets': freq_targets,
            'loss_dict': loss_dict,
            'loss': loss,
            'region_losses': region_losses,
            'moe_aux_loss': moe_aux_loss
        }
    
    def train_step(self, batch) -> Dict[str, float]:
        """æ‰§è¡Œä¸€æ­¥å¤šä»»åŠ¡è®­ç»ƒï¼ŒåŒ…æ‹¬æ—¶åŸŸå’Œé¢‘åŸŸä»»åŠ¡"""
        try:
            self.model.train()
            
            # å¤„ç†é‡æ„åçš„æ•°æ®æ ¼å¼ï¼š(data_batch, mask_batch)
            if isinstance(batch, tuple) and len(batch) == 2:
                # æ–°çš„æ•°æ®æ ¼å¼ï¼š(grouped_data_tensor, padding_mask_tensor)
                x_data, padding_mask = batch
                # x_data: [B, R, E, T] - å·²æŒ‰è„‘åŒºåˆ†ç»„
                # padding_mask: [B, R, E] - Trueè¡¨ç¤ºå¡«å……ä½ç½®
            elif isinstance(batch, (tuple, list)) and len(batch) > 0:
                # æ—§æ ¼å¼å…¼å®¹æ€§
                x_data = batch[0]
                # ä¸ºæ—§æ ¼å¼åˆ›å»ºé»˜è®¤padding mask
                B, R, E = x_data.shape[0], x_data.shape[1], x_data.shape[2]
                padding_mask = torch.zeros(B, R, E, dtype=torch.bool)
            elif isinstance(batch, torch.Tensor):
                # ç›´æ¥å¼ é‡è¾“å…¥
                x_data = batch
                B, R, E = x_data.shape[0], x_data.shape[1], x_data.shape[2]
                padding_mask = torch.zeros(B, R, E, dtype=torch.bool)
            else:
                raise TypeError(f"ä¸æ”¯æŒçš„æ‰¹æ¬¡æ•°æ®æ ¼å¼ï¼š{type(batch)}")
            
            # ç¡®ä¿æ•°æ®å’Œé®ç½©åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            x = x_data.to(self.device)  # [B, R, E, T]
            padding_mask = padding_mask.to(self.device)  # [B, R, E]
            
            # åº”ç”¨æ•°æ®å¢å¼ºï¼ˆåªåœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼‰
            # è®¾ç½®å¢å¼ºæ¨¡å—ä¸ºè®­ç»ƒæ¨¡å¼
            self.data_augmentation.train()
            x = self.data_augmentation(x)
            
            # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
            if self.use_amp:
                # è·å–æ•°æ®ç»´åº¦
                B, R, E, T = x.shape
                seq_len = R * E  # åºåˆ—é•¿åº¦ç°åœ¨æ˜¯è„‘åŒºæ•°Ã—ç”µææ•°
                
                # åˆ›å»ºæ—¶åŸŸæ©ç  - ç°åœ¨åŸºäºåºåˆ—é•¿åº¦R*E
                time_mask1, _ = create_symmetric_masks(
                    B, seq_len, 
                    mask_ratio=self.config.mask_ratio,
                    mask_strategy=self.config.mask_strategy,
                    device=self.device
                )
                
                # åˆ›å»ºé¢‘åŸŸæ©ç 
                freq_mask1 = create_frequency_masks(
                    B, self.config.n_freq_bands,
                    mask_ratio=self.config.freq_mask_ratio,
                    device=self.device
                )
                
                with autocast():
                    # æ‰§è¡Œæ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆä¸åŒ…æ‹¬æŸå¤±è®¡ç®—ï¼‰
                    time_pred1, time_pred2, freq_pred1, freq_pred2, moe_aux_loss = self.model(
                        x, time_mask=time_mask1, freq_mask=freq_mask1, padding_mask=padding_mask
                    )
                    
                    # ç›®æ ‡ç‰¹å¾
                    raw_model = self.model.module if isinstance(self.model, DDP) else self.model
                    time_targets, freq_targets = raw_model.get_targets(x, padding_mask=padding_mask)
                
                # åœ¨autocastä¸Šä¸‹æ–‡å¤–è®¡ç®—æŸå¤±ï¼Œç¡®ä¿æ•°å€¼ç¨³å®šæ€§
                loss_dict = self.loss_fn(
                    time_pred1, time_pred2, time_targets,
                    freq_pred1, freq_pred2, freq_targets,
                    moe_aux_loss=moe_aux_loss,
                    padding_mask=padding_mask
                )
                
                loss = loss_dict['loss']
                if loss.dim() > 0:  # å¦‚æœæŸå¤±ä¸æ˜¯æ ‡é‡ï¼ˆå¤šGPUæƒ…å†µï¼‰
                    loss = loss.mean()  # å–å¹³å‡å€¼
                loss = loss * self.loss_scale
                
                # è®¡ç®—è„‘åŒºçº§åˆ«çš„æŸå¤±
                region_losses = self._compute_region_losses(time_pred1, time_targets, freq_pred1, freq_targets)
                
                # æ¢¯åº¦ç¼©æ”¾å’Œåå‘ä¼ æ’­
                scaled_loss = self.scaler.scale(loss / self.gradient_accumulation_steps)
                scaled_loss.backward()
                
                # æ¢¯åº¦ç´¯ç§¯
                if (self.global_step + 1) % self.gradient_accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    if self.config.clip_grad > 0:
                        self.scaler.unscale_(self.optimizer)
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.clip_grad)
                        
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
                    
                    # æ·»åŠ GPUåŒæ­¥ç‚¹
                    torch.cuda.synchronize()
                    
                    # æ›´æ–°å­¦ä¹ ç‡ - ç§»åˆ°optimizer.step()åé¢ï¼Œæ·»åŠ æ­¥æ•°æ£€æŸ¥
                    self._safe_lr_step()
            else:
                # ä¸ä½¿ç”¨æ··åˆç²¾åº¦çš„æ ‡å‡†è®­ç»ƒ
                # æ‰§è¡Œæ ¸å¿ƒå‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—
                result = self._run_one_step(x, padding_mask)
                loss = result['loss']
                # ç¡®ä¿åœ¨å¤šGPUç¯å¢ƒä¸‹æŸå¤±æ˜¯æ ‡é‡
                if loss.dim() > 0:  # å¦‚æœæŸå¤±ä¸æ˜¯æ ‡é‡ï¼ˆå¤šGPUæƒ…å†µï¼‰
                    loss = loss.mean()  # å–å¹³å‡å€¼
                loss_dict = result['loss_dict']
                region_losses = result['region_losses']
                
                # åå‘ä¼ æ’­
                loss_grad = loss / self.gradient_accumulation_steps
                loss_grad.backward()
                
                # æ¢¯åº¦ç´¯ç§¯
                if (self.global_step + 1) % self.gradient_accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    if self.config.clip_grad > 0:
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.clip_grad)
                        
                    self.optimizer.step()
                    self.optimizer.zero_grad()
                    
                    # æ·»åŠ GPUåŒæ­¥ç‚¹
                    torch.cuda.synchronize()
                    
                    # æ›´æ–°å­¦ä¹ ç‡ - ç§»åˆ°optimizer.step()åé¢ï¼Œæ·»åŠ æ­¥æ•°æ£€æŸ¥
                    self._safe_lr_step()
            
            # æ›´æ–°å…¨å±€æ­¥æ•°
            self.global_step += 1
            
            # è¿”å›æŸå¤±æŒ‡æ ‡
            metrics = {
                'loss': loss.item() * self.gradient_accumulation_steps,
                'time_loss': loss_dict['time_loss'],
                'freq_loss': loss_dict['freq_loss'],
                'phase_loss': loss_dict['phase_loss'],
                'moe_loss': loss_dict.get('moe_loss', 0.0)
            }
            
            # æ·»åŠ è„‘åŒºçº§åˆ«çš„æŸå¤±
            for region_name, region_loss in region_losses.items():
                metrics[region_name] = region_loss
            
            # åœ¨DDPç¯å¢ƒä¸­èšåˆæŒ‡æ ‡
            aggregated_metrics = aggregate_metrics(metrics)
            
            # è®°å½•æŒ‡æ ‡åˆ°TensorBoardï¼ˆåªåœ¨ä¸»è¿›ç¨‹ä¸­ï¼‰
            if self.rank == 0 and self.global_step % 10 == 0:  # æ¯10æ­¥è®°å½•ä¸€æ¬¡ï¼Œé¿å…æ—¥å¿—è¿‡å¤§
                self.log_metrics(aggregated_metrics, self.global_step, prefix='train')
            
            return aggregated_metrics
            
        except RuntimeError as e:
            if "NCCL" in str(e) or "corrupted" in str(e):
                print_rank_0(f"æ•è·åˆ°NCCLé”™è¯¯: {str(e)}")
                # æ¸…ç†GPUå†…å­˜
                torch.cuda.empty_cache()
                gc.collect()
                
                # é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€
                self.optimizer.zero_grad()
                if self.use_amp and self.scaler is not None:
                    # é‡ç½®scalerçŠ¶æ€è€Œä¸æ˜¯æ›´æ–°
                    try:
                        # é‡æ–°åˆå§‹åŒ–scalerä»¥æ¸…é™¤æŸåçš„çŠ¶æ€
                        self.scaler = GradScaler(init_scale=2**16)
                        print_rank_0("scalerå·²é‡æ–°åˆå§‹åŒ–")
                    except Exception as scaler_error:
                        print_rank_0(f"è­¦å‘Š: scaleré‡æ–°åˆå§‹åŒ–å¤±è´¥: {str(scaler_error)}")
                
                # æ·»åŠ GPUåŒæ­¥
                torch.cuda.synchronize()
                
                # è¿”å›é»˜è®¤æŒ‡æ ‡ï¼Œé¿å…è®­ç»ƒä¸­æ–­
                return {
                    'loss': 1.0,
                    'time_loss': 0.5,
                    'freq_loss': 0.5,
                    'phase_loss': 0.0,
                    'moe_loss': 0.0
                }
            else:
                # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
                raise e
    
    def _safe_lr_step(self):
        """å®‰å…¨åœ°æ‰§è¡Œå­¦ä¹ ç‡è°ƒåº¦å™¨æ­¥è¿›ï¼Œé˜²æ­¢è¶…è¿‡æ€»æ­¥æ•°"""
        try:
            # æ£€æŸ¥OneCycleLRè°ƒåº¦å™¨çš„æ­¥æ•°æ˜¯å¦è¶…è¿‡æ€»æ­¥æ•°
            if hasattr(self.lr_scheduler, 'total_steps') and hasattr(self.lr_scheduler, 'last_epoch'):
                if self.lr_scheduler.last_epoch >= self.lr_scheduler.total_steps:
                    # å¦‚æœå·²ç»è¾¾åˆ°æ€»æ­¥æ•°ï¼Œåˆ‡æ¢åˆ°ç®€å•çš„è°ƒåº¦å™¨
                    self._switch_to_simple_scheduler()
                    return
            
            # æ­£å¸¸æ­¥è¿›
            self.lr_scheduler.step()
        except ValueError as e:
            if "Tried to step" in str(e) and "total steps" in str(e):
                # å¦‚æœæ­¥æ•°è¶…è¿‡æ€»æ­¥æ•°ï¼Œåˆ‡æ¢åˆ°ç®€å•çš„è°ƒåº¦å™¨
                print_rank_0(f"è­¦å‘Š: å­¦ä¹ ç‡è°ƒåº¦å™¨æ­¥æ•°è¶…é™ï¼Œåˆ‡æ¢åˆ°ç®€å•è°ƒåº¦å™¨ - {str(e)}")
                self._switch_to_simple_scheduler()
                return
            else:
                # å…¶ä»–é”™è¯¯é‡æ–°æŠ›å‡º
                raise e
        except Exception as e:
            print_rank_0(f"å­¦ä¹ ç‡è°ƒåº¦å™¨æ­¥è¿›æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            # å¯ä»¥é€‰æ‹©ç»§ç»­è®­ç»ƒæˆ–è€…æŠ›å‡ºé”™è¯¯
            pass
    
    def _switch_to_simple_scheduler(self):
        """åˆ‡æ¢åˆ°ç®€å•çš„å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        if not hasattr(self, '_switched_to_simple'):
            print_rank_0("æ­£åœ¨åˆ‡æ¢åˆ°ç®€å•çš„å­¦ä¹ ç‡è°ƒåº¦å™¨(ExponentialLR)...")
            current_lr = self.optimizer.param_groups[0]['lr']
            self.lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(
                self.optimizer, gamma=0.99  # æ¯æ­¥ä¹˜ä»¥0.99ï¼Œç¼“æ…¢è¡°å‡
            )
            # è®¾ç½®å½“å‰å­¦ä¹ ç‡
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = current_lr
            self._switched_to_simple = True
            print_rank_0(f"å·²åˆ‡æ¢åˆ°ç®€å•è°ƒåº¦å™¨ï¼Œå½“å‰å­¦ä¹ ç‡: {current_lr:.8f}")
        
        # æ‰§è¡Œç®€å•è°ƒåº¦å™¨çš„æ­¥è¿›
        self.lr_scheduler.step()
    
    def _compute_region_losses(self, time_pred, time_target, freq_pred=None, freq_target=None):
        """è®¡ç®—ä¸åŒè„‘åŒºçš„é‡å»ºæŸå¤±
        
        Args:
            time_pred: æ—¶åŸŸé¢„æµ‹ [B, R*E, T] æˆ– [B, R*E, D]
            time_target: æ—¶åŸŸç›®æ ‡ [B, R*E, T] æˆ– [B, R*E, D]  
            freq_pred: é¢‘åŸŸé¢„æµ‹ (å¯é€‰) [B, R*E, n_freq_bands]
            freq_target: é¢‘åŸŸç›®æ ‡ (å¯é€‰) [B, R*E, n_freq_bands]
            
        Returns:
            åŒ…å«ä¸åŒè„‘åŒºæŸå¤±çš„å­—å…¸ï¼Œé”®åæ ¼å¼ä¸º'region_time_loss'æˆ–'region_freq_loss'
        """
        region_losses = {}
        
        # æ£€æŸ¥é¢„æµ‹çš„åºåˆ—é•¿åº¦
        seq_len = time_pred.size(1)  # åºåˆ—é•¿åº¦ R*E
        
        # æ—¥å¿—è®°å½•ä»¥å¸®åŠ©è°ƒè¯•
        if self.global_step == 0:
            print_rank_0(f"åºåˆ—é•¿åº¦ (R*E): {seq_len}")
            print_rank_0(f"æ—¶åŸŸé¢„æµ‹å½¢çŠ¶: {time_pred.shape}, ç›®æ ‡å½¢çŠ¶: {time_target.shape}")
            if freq_pred is not None:
                print_rank_0(f"é¢‘åŸŸé¢„æµ‹å½¢çŠ¶: {freq_pred.shape}, ç›®æ ‡å½¢çŠ¶: {freq_target.shape}")
        
        # æ–°çš„æ•°æ®æ ¼å¼ä¸‹ï¼Œåºåˆ—ç»´åº¦æ˜¯ R*Eï¼ˆè„‘åŒºæ•°Ã—ç”µææ•°ï¼‰
        # è„‘åŒºæ•°å›ºå®šä¸º5ï¼Œç”µææ•°ä¸º24
        num_regions = self.config.num_regions  # 5
        max_electrodes_per_region = self.config.max_electrodes_per_region  # 24
        
        # ç¡®ä¿åºåˆ—é•¿åº¦åŒ¹é…é¢„æœŸ
        expected_seq_len = num_regions * max_electrodes_per_region
        if seq_len != expected_seq_len:
            print_rank_0(f"è­¦å‘Š: åºåˆ—é•¿åº¦ {seq_len} ä¸åŒ¹é…é¢„æœŸ {expected_seq_len}")
        
        # éå†è„‘åŒºå¹¶è®¡ç®—æ¯ä¸ªè„‘åŒºçš„æŸå¤±
        for region_idx, region_name in enumerate(['frontal', 'central', 'parietal', 'temporal', 'occipital']):
            # è®¡ç®—å½“å‰è„‘åŒºåœ¨åºåˆ—ä¸­çš„ä½ç½®èŒƒå›´
            start_idx = region_idx * max_electrodes_per_region
            end_idx = (region_idx + 1) * max_electrodes_per_region
            
            # æå–å½“å‰è„‘åŒºçš„é¢„æµ‹å’Œç›®æ ‡
            region_time_pred = time_pred[:, start_idx:end_idx]  # [B, E, T] or [B, E, D]
            region_time_target = time_target[:, start_idx:end_idx]  # [B, E, T] or [B, E, D]
            
            # è®¡ç®—æ—¶åŸŸæŸå¤±
            time_region_loss = F.mse_loss(region_time_pred, region_time_target)
            region_losses[f"{region_name}_time_loss"] = time_region_loss.item()
            
            # å¦‚æœæœ‰é¢‘åŸŸé¢„æµ‹ï¼Œä¹Ÿè®¡ç®—é¢‘åŸŸæŸå¤±
            if freq_pred is not None and freq_target is not None:
                region_freq_pred = freq_pred[:, start_idx:end_idx]  # [B, E, n_freq_bands]
                region_freq_target = freq_target[:, start_idx:end_idx]  # [B, E, n_freq_bands]
                
                freq_region_loss = F.mse_loss(region_freq_pred, region_freq_target)
                region_losses[f"{region_name}_freq_loss"] = freq_region_loss.item()
        
        return region_losses
    
    # éªŒè¯æ–¹æ³•å·²ç§»é™¤ - å°†åœ¨å•ç‹¬çš„éªŒè¯è„šæœ¬ä¸­å®ç°
    
    def train(self, train_loader: torch.utils.data.DataLoader,
              sampler: Optional[DistributedSampler] = None,
              num_epochs: int = 10,
              log_dir: str = './logs') -> Dict:
        
        # =================================================================
        # === æ­¥éª¤ 1: å®šä¹‰æ—¶é—´æ§åˆ¶çš„æ£€æŸ¥ç‚¹å‚æ•° ===
        # =================================================================
        checkpoint_interval_hours = 4  # æ‚¨å¯ä»¥è½»æ¾ä¿®æ”¹è¿™é‡Œï¼Œä¾‹å¦‚æ”¹ä¸º2ã€6æˆ–8å°æ—¶
        checkpoint_interval_seconds = checkpoint_interval_hours * 3600
        
        # ä¸ºäº†é¿å…åœ¨æ¯ä¸ªstepéƒ½æ£€æŸ¥æ—¶é—´å¸¦æ¥çš„å¼€é”€ï¼Œæˆ‘ä»¬æ¯éš”100æ­¥æ£€æŸ¥ä¸€æ¬¡
        check_time_every_n_steps = 100 
        # =================================================================
        
        # è®¾ç½®è®­ç»ƒæ•°æ®åŠ è½½å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
        try:
            self.setup_training(train_loader, num_epochs)
            print_rank_0("å­¦ä¹ ç‡è°ƒåº¦å™¨è®¾ç½®æˆåŠŸ")
        except Exception as e:
            print_rank_0(f"è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨å¤±è´¥: {str(e)}")
            print_rank_0("ä½¿ç”¨é»˜è®¤å­¦ä¹ ç‡è°ƒåº¦å™¨")
            self.lr_scheduler = torch.optim.lr_scheduler.StepLR(
                self.optimizer, step_size=30, gamma=0.1
            )
            self.steps_per_epoch = len(train_loader)
        if is_main_process():
            self.setup_logging(log_dir, record_graph=False)
        print_rank_0("\n" + "="*50)
        print_rank_0(f"{'DualDomain Neural Transformer MEM æ¨¡å‹è®­ç»ƒå¼€å§‹':^50}")
        print_rank_0("="*50)
        print_rank_0(f"{'æœ¬æ¬¡è¿è¡Œæ–‡ä»¶å¤¹':^50}")
        print_rank_0("-"*50)
        print_rank_0(f"{'è¿è¡Œæ–‡ä»¶å¤¹:':<15} {self.run_checkpoint_dir}")
        print_rank_0(f"{'æœ€ä½³æ¨¡å‹:':<15} {self.run_checkpoint_dir}/best_model.pt")
        print_rank_0(f"{'æœ€åæ¨¡å‹:':<15} {self.run_checkpoint_dir}/last_model.pt")
        print_rank_0("-"*50)
        print_rank_0(f"{'æ¨¡å‹å‚æ•°ç»Ÿè®¡':^50}")
        print_rank_0("-"*50)
        print_rank_0(f"{'æ€»å‚æ•°é‡:':<15} {self.param_stats['total']:,}")
        print_rank_0(f"{'å¯è®­ç»ƒå‚æ•°:':<15} {self.param_stats['trainable']:,}")
        print_rank_0(f"{'å†»ç»“å‚æ•°:':<15} {self.param_stats['frozen']:,}")
        print_rank_0(f"{'å†…å­˜å ç”¨(FP32):':<15} {self.param_stats['memory_fp32_mb']:.1f} MB")
        print_rank_0(f"{'å†…å­˜å ç”¨(FP16):':<15} {self.param_stats['memory_fp16_mb']:.1f} MB")
        print_rank_0("")
        print_rank_0(f"{'ä¸»è¦ç»„ä»¶å‚æ•°åˆ†å¸ƒ':^50}")
        print_rank_0("-"*50)
        if is_main_process():
            for name, params in sorted(self.param_stats['components'].items(), key=lambda x: x[1], reverse=True):
                percentage = params / self.param_stats['total'] * 100
                print_rank_0(f"{name:<20} {params:>12,} ({percentage:>5.1f}%)")
        print_rank_0("")
        print_rank_0(f"{'è®­ç»ƒé…ç½®ä¿¡æ¯':^50}")
        print_rank_0("-"*50)
        print_rank_0(f"{'è®­ç»ƒå‘¨æœŸ:':<15} {num_epochs}")
        print_rank_0(f"{'æ‰¹æ¬¡å¤§å°:':<15} {train_loader.batch_size}")
        print_rank_0(f"{'æœ‰æ•ˆæ‰¹æ¬¡å¤§å°:':<15} {self.effective_batch_size}")
        print_rank_0(f"{'è®¾å¤‡:':<15} {self.device}")
        if self.is_ddp:
            print_rank_0(f"{'DDPä¸–ç•Œå¤§å°:':<15} {dist.get_world_size()}")
            print_rank_0(f"{'DDPæ¨¡å¼:':<15} å¯ç”¨")
        else:
            print_rank_0(f"{'DDPæ¨¡å¼:':<15} ç¦ç”¨")
        print_rank_0(f"{'å­¦ä¹ ç‡:':<15} {self.config.lr}")
        print_rank_0(f"{'æ—¶åŸŸæŸå¤±æƒé‡:':<15} {self.config.time_loss_weight}")
        print_rank_0(f"{'é¢‘åŸŸæŸå¤±æƒé‡:':<15} {self.config.freq_loss_weight}")
        print_rank_0(f"{'æ··åˆç²¾åº¦:':<15} {'å¯ç”¨' if self.use_amp else 'ç¦ç”¨'}")
        print_rank_0(f"{'æ¢¯åº¦ç´¯ç§¯æ­¥æ•°:':<15} {self.gradient_accumulation_steps}")
        print_rank_0(f"{'æ¯ä¸ªå‘¨æœŸçš„æ­¥æ•°:':<15} {self.steps_per_epoch}")
        print_rank_0("="*50 + "\n")
        
        # =================================================================
        # === æ­¥éª¤ 2: ç»Ÿä¸€åˆå§‹åŒ–æ‰€æœ‰è®¡æ—¶å™¨ï¼ˆé¿å…é‡å¤æ—¶é—´è·å–ï¼‰===
        # =================================================================
        if self.training_start_time is None:  # åªåœ¨é¦–æ¬¡è®­ç»ƒæ—¶åˆå§‹åŒ–
            self.training_start_time = time.time()
        self.last_periodic_save_time = self.training_start_time  # é‡ç½®å‘¨æœŸæ€§ä¿å­˜è®¡æ—¶å™¨
        print_rank_0(f"â° è®­ç»ƒè®¡æ—¶å™¨å·²åˆå§‹åŒ–ï¼Œå‘¨æœŸæ€§ä¿å­˜é—´éš”: {checkpoint_interval_hours}å°æ—¶")
        # =================================================================
        avg_train_loss = float('nan')
        avg_time_loss = float('nan')
        avg_freq_loss = float('nan')
        avg_phase_loss = float('nan')
        for epoch in range(num_epochs):
            if sampler is not None:
                sampler.set_epoch(epoch)
            epoch_start_time = time.time()
            epoch_losses = []
            epoch_time_losses = []
            epoch_freq_losses = []
            epoch_phase_losses = []
            print_rank_0(f"\nEpoch {epoch+1}/{num_epochs}")
            print_rank_0("-"*50)
            total_batches = len(train_loader)
            progress_step = max(1, total_batches // 20)
            try:
                for batch_idx, batch in enumerate(train_loader):
                    metrics = self.train_step(batch)
                    epoch_losses.append(metrics['loss'])
                    epoch_time_losses.append(metrics['time_loss'])
                    epoch_freq_losses.append(metrics['freq_loss'])
                    epoch_phase_losses.append(metrics['phase_loss'])
                    if is_main_process() and (batch_idx % progress_step == 0 or batch_idx == total_batches - 1):
                        progress = min(20, int(batch_idx * 20 / total_batches) + 1)
                        elapsed = time.time() - epoch_start_time
                        current_lr = self.optimizer.param_groups[0]['lr']
                        print_rank_0(
                            f"\rè®­ç»ƒè¿›åº¦: [{'=' * progress}{' ' * (20-progress)}] {batch_idx+1}/{total_batches} | "
                            f"æ€»æŸå¤±: {metrics['loss']:.8f} | æ—¶åŸŸ: {metrics['time_loss']:.8f} | é¢‘åŸŸ: {metrics['freq_loss']:.8f} | "
                            f"LR: {current_lr:.8f} | ç”¨æ—¶: {elapsed:.1f}ç§’", end=""
                        )
                    if batch_idx % 50 == 0:
                        torch.cuda.empty_cache()
                        gc.collect()
                    
                    # =================================================================
                    # === æ­¥éª¤ 3: åµŒå…¥åŸºäºæ—¶é—´çš„å‘¨æœŸæ€§æ£€æŸ¥ç‚¹é€»è¾‘ ===
                    # =================================================================
                    # 1. æ¯éš” N æ­¥ï¼Œæ‰æ£€æŸ¥ä¸€æ¬¡æ—¶é—´ï¼Œä»¥é™ä½å¼€é”€
                    is_check_step = (self.global_step % check_time_every_n_steps == 0)

                    # 2. åˆ›å»ºä¸€ä¸ªä¿¡å·å¼ é‡ï¼Œç”¨äºåœ¨æ‰€æœ‰è¿›ç¨‹é—´åŒæ­¥"æ˜¯å¦ä¿å­˜"çš„å†³ç­–
                    save_signal = torch.tensor(0, device=self.device)
                    
                    # 3. åªæœ‰ä¸»è¿›ç¨‹(rank 0)æ£€æŸ¥æ—¶é—´å¹¶åšå‡ºå†³ç­–
                    if self.is_ddp and self.rank == 0 and is_check_step:
                        current_time = time.time()
                        if (current_time - self.last_periodic_save_time) >= checkpoint_interval_seconds:
                            save_signal[0] = 1 # å†³ç­–ï¼šæ˜¯æ—¶å€™ä¿å­˜äº†ï¼

                    # (åœ¨éDDPæ¨¡å¼ä¸‹ï¼Œä¹Ÿè¿›è¡Œæ£€æŸ¥)
                    if not self.is_ddp and is_check_step:
                         current_time = time.time()
                         if (current_time - self.last_periodic_save_time) >= checkpoint_interval_seconds:
                            save_signal[0] = 1

                    # 4. å¦‚æœæ˜¯DDPç¯å¢ƒï¼Œå°† rank 0 çš„å†³ç­–å¹¿æ’­ç»™æ‰€æœ‰å…¶ä»–è¿›ç¨‹
                    if self.is_ddp:
                        dist.broadcast(save_signal, src=0)
                    
                    # 5. å¦‚æœä¿¡å·ä¸º1 (éœ€è¦ä¿å­˜)ï¼Œåˆ™æ‰€æœ‰è¿›ç¨‹éƒ½æ‰§è¡Œç›¸åº”æ“ä½œ
                    if save_signal.item() == 1:
                        # åªæœ‰ä¸»è¿›ç¨‹è´Ÿè´£å†™å…¥æ–‡ä»¶
                        if is_main_process():
                            periodic_ckpt_path = f"{self.run_checkpoint_dir}/periodic_checkpoint.pt"
                            print_rank_0(f"\nâ° æ—¶é—´è¾¾åˆ° {checkpoint_interval_hours} å°æ—¶ï¼Œæ­£åœ¨ä¿å­˜å‘¨æœŸæ€§æ£€æŸ¥ç‚¹åˆ° {periodic_ckpt_path}...")
                            try:
                                self.save_checkpoint(periodic_ckpt_path)
                                # å…³é”®ï¼šåªæœ‰åœ¨æˆåŠŸä¿å­˜åï¼Œæ‰é‡ç½®è®¡æ—¶å™¨
                                self.last_periodic_save_time = time.time()
                                elapsed_hours = (self.last_periodic_save_time - self.training_start_time) / 3600
                                print_rank_0(f"âœ… å‘¨æœŸæ€§æ£€æŸ¥ç‚¹ä¿å­˜æˆåŠŸ (è®­ç»ƒå·²è¿›è¡Œ {elapsed_hours:.1f} å°æ—¶)")
                            except Exception as e:
                                print_rank_0(f"âŒ ä¿å­˜å‘¨æœŸæ€§æ£€æŸ¥ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        
                        # 6. è®¾ç½®åŒæ­¥æ …æ ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½ç­‰å¾… rank 0 ä¿å­˜å®Œæ¯•åå†ç»§ç»­
                        if self.is_ddp:
                            dist.barrier()
                    # =================================================================
            except torch.cuda.OutOfMemoryError as e:
                print_rank_0(f"\nâŒ CUDAæ˜¾å­˜ä¸è¶³é”™è¯¯: {str(e)}")
                print_rank_0("âŒ æ— æ³•ç»§ç»­è®­ç»ƒï¼Œç¨‹åºå°†ç»ˆæ­¢ä»¥é˜²æ­¢åç»­é”™è¯¯")
                torch.cuda.empty_cache()
                gc.collect()
                raise e
            except Exception as e:
                print_rank_0(f"\nâš ï¸ è®­ç»ƒæœŸé—´å‘ç”Ÿå…¶ä»–é”™è¯¯: {str(e)}")
                print_rank_0("ğŸ”„ å°è¯•ç»§ç»­è®­ç»ƒ...")
                torch.cuda.empty_cache()
                gc.collect()
                self.optimizer.zero_grad()
                if self.use_amp and self.scaler is not None:
                    try:
                        # é‡æ–°åˆå§‹åŒ–scalerä»¥æ¸…é™¤å¯èƒ½çš„é”™è¯¯çŠ¶æ€
                        self.scaler = GradScaler(init_scale=2**16)
                        print_rank_0("scalerå·²é‡æ–°åˆå§‹åŒ–")
                    except Exception as scaler_error:
                        print_rank_0(f"è­¦å‘Š: scaleré‡æ–°åˆå§‹åŒ–å¤±è´¥: {str(scaler_error)}")
                torch.cuda.synchronize()
                continue
            # 1. ç»Ÿè®¡æœ¬åœ°æ‰¹æ¬¡æ•°å’ŒæŸå¤±å’Œ
            local_count = torch.tensor([len(epoch_losses)], dtype=torch.float32, device=self.device)
            local_loss = torch.tensor([sum(epoch_losses) if len(epoch_losses) > 0 else 0.0], dtype=torch.float32, device=self.device)
            local_time_loss = torch.tensor([sum(epoch_time_losses) if len(epoch_time_losses) > 0 else 0.0], dtype=torch.float32, device=self.device)
            local_freq_loss = torch.tensor([sum(epoch_freq_losses) if len(epoch_freq_losses) > 0 else 0.0], dtype=torch.float32, device=self.device)
            local_phase_loss = torch.tensor([sum(epoch_phase_losses) if len(epoch_phase_losses) > 0 else 0.0], dtype=torch.float32, device=self.device)
            local_stats = torch.cat([local_count, local_loss, local_time_loss, local_freq_loss, local_phase_loss], dim=0)
            if dist.is_initialized():
                dist.all_reduce(local_stats, op=dist.ReduceOp.SUM)
            total_count = local_stats[0].item()
            total_loss = local_stats[1].item()
            total_time_loss = local_stats[2].item()
            total_freq_loss = local_stats[3].item()
            total_phase_loss = local_stats[4].item()
            if total_count > 0:
                avg_train_loss = total_loss / total_count
                avg_time_loss = total_time_loss / total_count
                avg_freq_loss = total_freq_loss / total_count
                avg_phase_loss = total_phase_loss / total_count
            else:
                avg_train_loss = float('nan')
                avg_time_loss = float('nan')
                avg_freq_loss = float('nan')
                avg_phase_loss = float('nan')
            if is_main_process():
                print_rank_0("\n" + "-"*50)
                print_rank_0(f"{'Epoch æ€»ç»“':^50}")
                print_rank_0(f"{'è®­ç»ƒæ€»æŸå¤±:':<15} {avg_train_loss:.8f}")
                print_rank_0(f"{'è®­ç»ƒæ—¶åŸŸæŸå¤±:':<15} {avg_time_loss:.8f}")
                print_rank_0(f"{'è®­ç»ƒé¢‘åŸŸæŸå¤±:':<15} {avg_freq_loss:.8f}")
                print_rank_0(f"{'è®­ç»ƒç›¸ä½æŸå¤±:':<15} {avg_phase_loss:.8f}")
                print_rank_0(f"{'å½“å‰å­¦ä¹ ç‡:':<15} {self.optimizer.param_groups[0]['lr']:.8f}")
                print_rank_0(f"{'æœ¬è½®ç”¨æ—¶:':<15} {time.time() - epoch_start_time:.1f}ç§’")
                print_rank_0("-"*50)
            torch.cuda.empty_cache()
            gc.collect()
        total_training_time = time.time() - self.training_start_time
        hours, remainder = divmod(total_training_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        print_rank_0("\n" + "="*50)
        print_rank_0(f"{'è®­ç»ƒå®Œæˆ':^50}")
        print_rank_0("-"*50)
        print_rank_0(f"{'æ€»è®­ç»ƒæ—¶é—´:':<15} {int(hours)}å°æ—¶ {int(minutes)}åˆ† {seconds:.1f}ç§’")
        final_loss_str = f"{avg_train_loss:.8f}" if not math.isnan(avg_train_loss) else "æœªè®¡ç®— (æ— æœ‰æ•ˆè®­ç»ƒæ•°æ®)"
        print_rank_0(f"{'æœ€ç»ˆè®­ç»ƒæŸå¤±:':<15} {final_loss_str}")
        print_rank_0(f"{'æœ€ä½³è®­ç»ƒæŸå¤±:':<15} {self.best_loss:.8f}")
        print_rank_0(f"{'è¿è¡Œæ–‡ä»¶å¤¹:':<15} {self.run_checkpoint_dir}")
        print_rank_0(f"{'æœ€ä½³æ¨¡å‹:':<15} {self.run_checkpoint_dir}/best_model.pt")
        print_rank_0(f"{'æœ€åæ¨¡å‹:':<15} {self.run_checkpoint_dir}/last_model.pt")
        print_rank_0(f"{'å‘¨æœŸæ€§æ£€æŸ¥ç‚¹:':<15} {self.run_checkpoint_dir}/periodic_checkpoint.pt")
        print_rank_0("="*50)
        if self.tensorboard_writer is not None:
            self.tensorboard_writer.close()
        return self.metrics
    
    def save_checkpoint(self, filename: str):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        
        # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œä¿å­˜æ“ä½œï¼Œä½†æ‰€æœ‰è¿›ç¨‹éƒ½éœ€ç­‰å¾…
        if self.is_ddp:
            dist.barrier() # ç¡®ä¿æ‰€æœ‰è¿›ç¨‹åŒæ­¥

        if not is_main_process():
            return # éä¸»è¿›ç¨‹ç›´æ¥è¿”å›

        try:
            # è·å–åŸå§‹æ¨¡å‹ï¼ˆå»é™¤DDPåŒ…è£…ï¼‰
            raw_model = self.model.module if self.is_ddp else self.model

            # åˆ›å»ºæ£€æŸ¥ç‚¹å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨ state_dict()ï¼Œæ— éœ€æ‰‹åŠ¨ç§»è‡³CPU
            checkpoint = {
                'model_state_dict': raw_model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.lr_scheduler.state_dict(),
                'global_step': self.global_step,
                'config': self.config, # ç›´æ¥ä¿å­˜configå¯¹è±¡
                'metrics': self.metrics,
                'best_loss': self.best_loss,
            }
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è¿›è¡ŒåŸå­ä¿å­˜ï¼Œé˜²æ­¢å†™å…¥ä¸­æ–­å¯¼è‡´æ–‡ä»¶æŸå
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            temp_filename = filename + '.tmp'
            torch.save(checkpoint, temp_filename)
            
            # åŸå­æ€§åœ°é‡å‘½åæ–‡ä»¶
            os.rename(temp_filename, filename)
            
            print_rank_0(f"âœ“ æ¨¡å‹æ£€æŸ¥ç‚¹å·²æˆåŠŸä¿å­˜åˆ°: {filename}")

        except Exception as e:
            print_rank_0(f"âŒ ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹å¤±è´¥: {str(e)}")
            # å°è¯•æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_filename = filename + '.tmp'
            if os.path.exists(temp_filename):
                try:
                    os.remove(temp_filename)
                except OSError:
                    pass
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä»¥ä¾¿å¤–éƒ¨é‡è¯•é€»è¾‘å¯ä»¥æ•è·
            raise e

        # === ä¿®æ”¹/æ·»åŠ  ===
        # æ­¥éª¤ 2: å†æ¬¡è®¾ç½®ä¸€ä¸ªé›†åˆç‚¹ï¼Œç¡®ä¿ rank 0 å·²ç»å®Œæˆäº†ä¿å­˜æ“ä½œï¼Œ
        # ä¹‹åæ‰€æœ‰è¿›ç¨‹å†ä¸€èµ·å®‰å…¨åœ°è¿›å…¥ä¸‹ä¸€ä¸ªè®­ç»ƒå‘¨æœŸã€‚
        if dist.is_initialized():
            dist.barrier()
        # === ä¿®æ”¹ç»“æŸ ===
    
    def load_checkpoint(self, filename: str):
        """åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹"""
        if not os.path.exists(filename):
            print_rank_0(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
            return False
        
        checkpoint = torch.load(filename, map_location=self.device)
        
        # æ ¹æ®å½“å‰æ˜¯å¦ä½¿ç”¨DDPæ¥åŠ è½½æ¨¡å‹çŠ¶æ€
        if isinstance(self.model, DDP):
            # å½“å‰ä½¿ç”¨DDPï¼Œç›´æ¥åŠ è½½åˆ°module
            self.model.module.load_state_dict(checkpoint['model_state_dict'])
        else:
            # å½“å‰ä½¿ç”¨å•GPUï¼Œç›´æ¥åŠ è½½
            self.model.load_state_dict(checkpoint['model_state_dict'])
        
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        self.global_step = checkpoint['global_step']
        self.metrics = checkpoint['metrics']
        
        if 'best_loss' in checkpoint:
            self.best_loss = checkpoint['best_loss']
        
        if 'run_checkpoint_dir' in checkpoint:
            original_run_dir = checkpoint['run_checkpoint_dir']
            print_rank_0(f"åŸå§‹è¿è¡Œæ–‡ä»¶å¤¹: {original_run_dir}")
        
        # æ˜¾ç¤ºåˆ†å¸ƒå¼ä¿¡æ¯
        if 'is_ddp' in checkpoint and 'world_size' in checkpoint:
            original_is_ddp = checkpoint['is_ddp']
            original_world_size = checkpoint['world_size']
            print_rank_0(f"åŸå§‹è®­ç»ƒ: {'DDP' if original_is_ddp else 'å•GPU'} (ä¸–ç•Œå¤§å°: {original_world_size})")
            current_world_size = dist.get_world_size() if self.is_ddp else 1
            print_rank_0(f"å½“å‰è®­ç»ƒ: {'DDP' if self.is_ddp else 'å•GPU'} (ä¸–ç•Œå¤§å°: {current_world_size})")
        
        print_rank_0(f"ä» {filename} åŠ è½½æ£€æŸ¥ç‚¹æˆåŠŸï¼Œå…¨å±€æ­¥æ•°: {self.global_step}ï¼Œæœ€ä½³æŸå¤±: {self.best_loss:.8f}")
        return True

    def get_model(self) -> DualDomainTransformerMEM:
        """è¿”å›è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆå»é™¤DDPåŒ…è£…ï¼‰"""
        return self.model.module if isinstance(self.model, DDP) else self.model


if __name__ == "__main__":
    # å°è¯•è®¾ç½®DDPç¯å¢ƒ
    try:
        rank, local_rank, world_size = setup_ddp()
        device = torch.device(f"cuda:{local_rank}")
        print_rank_0(f"DDPåˆå§‹åŒ–æˆåŠŸ: rank={rank}, local_rank={local_rank}, world_size={world_size}")
    except KeyError as e:
        print_rank_0(f"DDPç¯å¢ƒå˜é‡ç¼ºå¤±: {e}")
        print_rank_0("ä½¿ç”¨å•GPUæ¨¡å¼")
        rank, local_rank, world_size = 0, 0, 1
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # é…ç½®å‚æ•°
    config = ModelConfig()
    
    # è¾“å…¥å‚æ•° - æ”¯æŒç¯å¢ƒå˜é‡
    config.embed_dim = int(os.environ.get('EMBED_DIM', '256'))        # åµŒå…¥ç»´åº¦
    config.num_heads = int(os.environ.get('NUM_HEADS', '8'))         # æ³¨æ„åŠ›å¤´æ•°
    config.depth = int(os.environ.get('DEPTH', '2'))                 # Transformerå±‚æ•°

        
    # æ­£åˆ™åŒ–å‚æ•°
    config.drop_rate = float(os.environ.get('DROP_RATE', '0.2'))     # dropoutç‡
    config.attn_drop_rate = float(os.environ.get('ATTN_DROP_RATE', '0.2')) # æ³¨æ„åŠ›dropoutç‡
    config.drop_path_rate = float(os.environ.get('DROP_PATH_RATE', '0.2')) # éšæœºæ·±åº¦ç‡

        
    # åˆå§‹åŒ–å‚æ•°
    config.init_std = float(os.environ.get('INIT_STD', '0.02'))     # åˆå§‹åŒ–æ ‡å‡†å·®
    config.use_abs_pos = os.environ.get('USE_ABS_POS', 'False').lower() == 'true'    # æ˜¯å¦ä½¿ç”¨ç»å¯¹ä½ç½®ç¼–ç 
    config.use_rel_pos = os.environ.get('USE_REL_POS', 'True').lower() == 'true'   # æ˜¯å¦ä½¿ç”¨ç›¸å¯¹ä½ç½®ç¼–ç 
    config.use_time_embed = os.environ.get('USE_TIME_EMBED', 'True').lower() == 'true' # æ˜¯å¦ä½¿ç”¨æ—¶é—´åµŒå…¥
        
    # æ©ç å‚æ•°
    config.mask_ratio = float(os.environ.get('MASK_RATIO', '0.15'))    # æ©ç æ¯”ä¾‹
    config.mask_strategy = os.environ.get('MASK_STRATEGY', 'random')  # æ©ç ç­–ç•¥: random, block, structure
    config.mask_noise_ratio = float(os.environ.get('MASK_NOISE_RATIO', '0.005')) # æ©ç å™ªå£°æ¯”ä¾‹
        
    # MoE (Mixture of Experts) ç›¸å…³å‚æ•°
    config.use_moe = os.environ.get('USE_MOE', 'True').lower() == 'true'                 # æ˜¯å¦å¯ç”¨MoEæ›¿æ¢FFN
    config.num_experts = int(os.environ.get('NUM_EXPERTS', '4'))                # ä¸“å®¶çš„æ•°é‡
    config.top_k_experts = int(os.environ.get('TOP_K_EXPERTS', '2'))              # æ¯ä¸ªtokenæ¿€æ´»çš„ä¸“å®¶æ•°é‡
    config.moe_aux_loss_coeff = float(os.environ.get('MOE_AUX_LOSS_COEFF', '0.01'))      # è´Ÿè½½å‡è¡¡è¾…åŠ©æŸå¤±çš„æƒé‡ç³»æ•°
        
    # è®­ç»ƒå‚æ•°
    config.lr = float(os.environ.get('LEARNING_RATE', '1e-4'))            # å­¦ä¹ ç‡
    config.weight_decay = float(os.environ.get('WEIGHT_DECAY', '1e-4'))  # æƒé‡è¡°å‡
    config.warmup_epochs = int(os.environ.get('WARMUP_EPOCHS', '5'))     # é¢„çƒ­å‘¨æœŸ
    config.use_amp = os.environ.get('USE_AMP', 'True').lower() == 'true'        # æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    config.clip_grad = float(os.environ.get('CLIP_GRAD', '0.1'))     # æ¢¯åº¦è£å‰ªé˜ˆå€¼
    config.freq_eval = os.environ.get('FREQ_EVAL', 'True').lower() == 'true'     # æ˜¯å¦è¿›è¡Œé¢‘åŸŸè¯„ä¼°
        
    # æ•°æ®æ ‡å‡†åŒ–å‚æ•°
    config.use_layer_norm = os.environ.get('USE_LAYER_NORM', 'True').lower() == 'true'  # æ˜¯å¦ä½¿ç”¨å±‚å½’ä¸€åŒ–
    config.use_batch_norm = os.environ.get('USE_BATCH_NORM', 'True').lower() == 'true'  # å¯ç”¨æ‰¹å½’ä¸€åŒ–
    config.eps = float(os.environ.get('EPS', '1e-8'))           # æ•°å€¼ç¨³å®šæ€§å‚æ•°
        
    # é€šé“åµŒå…¥å‚æ•°
    config.use_channel_embed = os.environ.get('USE_CHANNEL_EMBED', 'True').lower() == 'true'    # æ˜¯å¦ä½¿ç”¨é€šé“åµŒå…¥
    config.channel_embed_dim = int(os.environ.get('CHANNEL_EMBED_DIM', '32'))      # é€šé“åµŒå…¥ç»´åº¦
    config.num_brain_regions = int(os.environ.get('NUM_BRAIN_REGIONS', '5'))       # è„‘åŒºæ•°é‡ï¼ˆé¢å¶ã€ä¸­å¤®åŒºã€é¡¶å¶ã€æ•å¶ã€é¢å¶ï¼‰
        
    # æ·»åŠ é¢‘åŸŸç›¸å…³å‚æ•°
    config.freq_mask_ratio = float(os.environ.get('FREQ_MASK_RATIO', '0.3'))  # é¢‘åŸŸæ©ç æ¯”ä¾‹
    config.time_loss_weight = float(os.environ.get('TIME_LOSS_WEIGHT', '0.9'))  # é»˜è®¤å€¼ä» 0.7 æé«˜åˆ° 0.9
    config.freq_loss_weight = float(os.environ.get('FREQ_LOSS_WEIGHT', '0.1'))  # é»˜è®¤å€¼ä» 0.3 é™ä½åˆ° 0.1
        
    # æ·»åŠ åˆ†å±‚GATç›¸å…³å‚æ•°
    config.channel_gat_initial_dim = int(os.environ.get('CHANNEL_GAT_INITIAL_DIM', '32'))  # åˆå§‹ç”µæåµŒå…¥ç»´åº¦
    config.intra_region_gat_heads = int(os.environ.get('INTRA_REGION_GAT_HEADS', '4'))    # è„‘åŒºå†…GATæ³¨æ„åŠ›å¤´æ•°
    config.intra_region_gat_dim_per_head = int(os.environ.get('INTRA_REGION_GAT_DIM_PER_HEAD', '32'))  # è„‘åŒºå†…GATæ¯ä¸ªå¤´çš„ç»´åº¦
    config.region_agg_attention_dim = int(os.environ.get('REGION_AGG_ATTENTION_DIM', '64'))  # è„‘åŒºèšåˆæ³¨æ„åŠ›ç»´åº¦
    config.inter_region_gat_heads = int(os.environ.get('INTER_REGION_GAT_HEADS', '4'))    # è„‘åŒºé—´GATæ³¨æ„åŠ›å¤´æ•°
    config.inter_region_gat_dim_per_head = int(os.environ.get('INTER_REGION_GAT_DIM_PER_HEAD', '64'))  # è„‘åŒºé—´GATæ¯ä¸ªå¤´çš„ç»´åº¦
    
    # æ·»åŠ è®­ç»ƒå‚æ•°
    config.batch_size = int(os.environ.get('BATCH_SIZE', '32'))         # æ‰¹æ¬¡å¤§å°
    config.debug = os.environ.get('DEBUG', 'False').lower() == 'true'           # è°ƒè¯•æ¨¡å¼
    
    # æ·»åŠ ä¸€äº›æ–­è¨€æ£€æŸ¥ï¼Œç¡®ä¿å‚æ•°è®¾ç½®åˆç†
    assert config.batch_size > 0, "æ‰¹æ¬¡å¤§å°å¿…é¡»å¤§äº0"
    assert config.embed_dim % config.num_heads == 0, "åµŒå…¥ç»´åº¦å¿…é¡»æ˜¯æ³¨æ„åŠ›å¤´æ•°çš„æ•´æ•°å€"
    
    # æ‰“å°è®¾å¤‡ä¿¡æ¯
    print_rank_0(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ‰“å°GPUä¿¡æ¯
    if torch.cuda.is_available():
        if rank == 0:
            num_gpus = torch.cuda.device_count()
            print_rank_0(f"å¯ç”¨GPUæ•°é‡: {num_gpus}")
            for i in range(num_gpus):
                print_rank_0(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
                print_rank_0(f"    æ˜¾å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
    else:
        print_rank_0("CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print_rank_0("\n=== æ¨¡å‹é…ç½®ä¿¡æ¯ ===")
    if rank == 0:
        for key, value in config.__dict__.items():
            print_rank_0(f"{key}: {value}")
    
    # æ­¥éª¤1ï¼šåˆ›å»ºåŸå§‹æ¨¡å‹å®ä¾‹
    model = DualDomainTransformerMEM(config).to(device)
    print_rank_0(f"æ¨¡å‹å·²åˆ›å»ºå¹¶ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
    
    # æ­¥éª¤1.5ï¼šåº”ç”¨torch.compileä¼˜åŒ–
    # try:
    #     print_rank_0("æ­£åœ¨åº”ç”¨torch.compileä¼˜åŒ–...")
    #     model = torch.compile(model)
    #     print_rank_0("torch.compileä¼˜åŒ–å·²æˆåŠŸåº”ç”¨")
    # except Exception as e:
    #     print_rank_0(f"torch.compileä¼˜åŒ–å¤±è´¥: {str(e)}")
    #     print_rank_0("ç»§ç»­ä½¿ç”¨æœªä¼˜åŒ–çš„æ¨¡å‹")
    
    # æ­¥éª¤2ï¼šDDPå°è£…ï¼ˆå¦‚æœåœ¨DDPç¯å¢ƒä¸­ï¼‰
    if dist.is_initialized():
        ddp_model = DDP(model, device_ids=[local_rank], find_unused_parameters=True)
        print_rank_0(f"æ¨¡å‹å·²ä½¿ç”¨DDPå°è£…åœ¨è®¾å¤‡ {local_rank}")
    else:
        ddp_model = model
        print_rank_0("å•GPUæ¨¡å¼ï¼Œæ— éœ€DDPå°è£…")
    
    # æ­¥éª¤3ï¼šåˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨DDPå°è£…åçš„æ¨¡å‹å‚æ•°ï¼‰
    optimizer = torch.optim.AdamW(
        ddp_model.parameters(),
        lr=config.lr,
        weight_decay=config.weight_decay,
        betas=(0.9, 0.95),
        eps=1e-8
    )
    print_rank_0(f"ä¼˜åŒ–å™¨å·²åˆ›å»ºï¼Œå­¦ä¹ ç‡: {config.lr}")
    
    # æ­¥éª¤4ï¼šåˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
    trainer = DualDomainTrainer(ddp_model, optimizer, config, device, rank)
    print_rank_0("è®­ç»ƒå™¨å·²åˆ›å»º")
    
    # è®¡ç®—æ¨¡å‹å‚æ•°é‡
    def count_parameters(model):
        """è®¡ç®—æ¨¡å‹å‚æ•°é‡"""
        # è·å–åŸå§‹æ¨¡å‹ï¼ˆå»é™¤DDPåŒ…è£…ï¼‰
        raw_model = model.module if isinstance(model, DDP) else model
        
        total_params = sum(p.numel() for p in raw_model.parameters())
        trainable_params = sum(p.numel() for p in raw_model.parameters() if p.requires_grad)
        frozen_params = total_params - trainable_params
        
        # æŒ‰æ¨¡å—ç»Ÿè®¡å‚æ•°é‡
        module_params = {}
        for name, module in raw_model.named_modules():
            if len(list(module.children())) == 0:  # å¶å­æ¨¡å—
                params = sum(p.numel() for p in module.parameters())
                if params > 0:
                    module_params[name] = params
        
        return {
            'total': total_params,
            'trainable': trainable_params, 
            'frozen': frozen_params,
            'modules': module_params
        }
    
    # æ‰“å°æ¨¡å‹å‚æ•°ç»Ÿè®¡
    param_stats = count_parameters(ddp_model)
    print_rank_0("\n" + "="*60)
    print_rank_0(f"{'æ¨¡å‹å‚æ•°ç»Ÿè®¡':^60}")
    print_rank_0("="*60)
    print_rank_0(f"{'æ€»å‚æ•°é‡:':<20} {param_stats['total']:,}")
    print_rank_0(f"{'å¯è®­ç»ƒå‚æ•°:':<20} {param_stats['trainable']:,}")
    print_rank_0(f"{'å†»ç»“å‚æ•°:':<20} {param_stats['frozen']:,}")
    print_rank_0(f"{'å‚æ•°å¤§å°:':<20} {param_stats['total'] * 4 / 1024 / 1024:.2f} MB (FP32)")
    print_rank_0(f"{'å‚æ•°å¤§å°:':<20} {param_stats['total'] * 2 / 1024 / 1024:.2f} MB (FP16)")
    
    # æ‰“å°ä¸»è¦æ¨¡å—çš„å‚æ•°é‡ï¼ˆä»…åœ¨ä¸»è¿›ç¨‹ä¸­ï¼‰
    print_rank_0("\n" + "-"*60)
    print_rank_0(f"{'ä¸»è¦æ¨¡å—å‚æ•°åˆ†å¸ƒ':^60}")
    print_rank_0("-"*60)
    
    # æŒ‰å‚æ•°é‡æ’åºå¹¶æ˜¾ç¤ºå‰10ä¸ªæœ€å¤§çš„æ¨¡å—ï¼ˆä»…åœ¨ä¸»è¿›ç¨‹ä¸­ï¼‰
    if is_main_process():
        sorted_modules = sorted(param_stats['modules'].items(), key=lambda x: x[1], reverse=True)
        for i, (name, params) in enumerate(sorted_modules[:10]):
            percentage = params / param_stats['total'] * 100
            print_rank_0(f"{name:<40} {params:>10,} ({percentage:>5.1f}%)")
        
        if len(sorted_modules) > 10:
            remaining_params = sum(params for _, params in sorted_modules[10:])
            remaining_percentage = remaining_params / param_stats['total'] * 100
            print_rank_0(f"{'å…¶ä»–æ¨¡å—':<40} {remaining_params:>10,} ({remaining_percentage:>5.1f}%)")
    
    print_rank_0("="*60)
    
    # å‡†å¤‡æ•°æ® - æ”¯æŒç¯å¢ƒå˜é‡
    # å¦‚æœè¦ä½¿ç”¨åˆå¹¶æ–‡ä»¶ï¼Œç¡®ä¿è·¯å¾„æŒ‡å‘åŒ…å«åˆå¹¶æ–‡ä»¶çš„ç›®å½•
    data_path = os.environ.get('DATA_PATH', "E:\BFM")
    print_rank_0(f"\næ­£åœ¨åŠ è½½æ•°æ®: {data_path}")

    # 1. å®ä¾‹åŒ–æ•°æ®é›†ï¼Œä¾› DDP Sampler ä½¿ç”¨
    # è¿™ä¸€æ­¥å¯¹äºæ­£ç¡®è®¡ç®—æ•°æ®é›†æ€»é•¿åº¦å’Œåˆ†å¸ƒå¼é‡‡æ ·è‡³å…³é‡è¦
    dataset = EEGBrainRegionDataset(data_path)

    # 2. åˆ›å»º DDP Sampler
    sampler = DistributedSampler(
        dataset,
        num_replicas=world_size,
        rank=rank,
        shuffle=True,
        drop_last=True
    )

    # 3. ç›´æ¥åˆ›å»ºDataLoaderï¼Œé‡ç”¨å·²æœ‰çš„æ•°æ®é›†å®ä¾‹
    from load_slurm_1 import custom_collate_fn
    
    # æ ¹æ®æœåŠ¡å™¨é…ç½®ä¼˜åŒ–æ•°æ®åŠ è½½å™¨è®¾ç½®
    # æœåŠ¡å™¨é…ç½®ï¼šæ¯GPUé…32ä¸ªCPUæ ¸å¿ƒ
    num_workers = int(os.environ.get('NUM_WORKERS', '8'))  # é»˜è®¤8ä¸ªworkerï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡è°ƒæ•´
    
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ä¸è¶…è¿‡åˆç†èŒƒå›´
    if num_workers > 16:
        print_rank_0(f"è­¦å‘Š: num_workers={num_workers} å¯èƒ½è¿‡é«˜ï¼Œå»ºè®®è®¾ç½®ä¸º16ä»¥ä¸‹")
    
    print_rank_0(f"æ•°æ®åŠ è½½é…ç½®: num_workers={num_workers}, æœåŠ¡å™¨CPUæ ¸å¿ƒå……è¶³")
    
    train_loader = DataLoader(
        dataset,  # é‡ç”¨å·²åˆ›å»ºçš„æ•°æ®é›†å®ä¾‹ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
        batch_size=config.batch_size,
        sampler=sampler,
        num_workers=num_workers,  # åˆ©ç”¨å¤šè¿›ç¨‹åŠ è½½æå‡æ€§èƒ½
        pin_memory=True,
        collate_fn=custom_collate_fn,
        persistent_workers=True if num_workers > 0 else False,  # ä¿æŒworkerè¿›ç¨‹æ´»è·ƒï¼Œå‡å°‘åˆ›å»ºå¼€é”€
        prefetch_factor=2 if num_workers > 0 else 2  # é¢„å–æ‰¹æ¬¡æ•°é‡
    )
    print_rank_0(f"æ•°æ®åŠ è½½å™¨å·²åˆ›å»º: æ ·æœ¬æ•°={len(dataset)}, æ‰¹æ¬¡å¤§å°={config.batch_size}")
    
    # è®¾ç½®è®­ç»ƒå‚æ•° - æ”¯æŒç¯å¢ƒå˜é‡
    num_epochs = int(os.environ.get('NUM_EPOCHS', '10'))
    log_dir = os.environ.get('LOG_DIR', "./logs")
    
    # æ‰“å°åˆ†éš”çº¿å’Œè®­ç»ƒä¿¡æ¯
    print_rank_0("\n" + "="*50)
    print_rank_0(f"å¼€å§‹è®­ç»ƒ DualDomain Neural Transformer MEM æ¨¡å‹")
    print_rank_0(f"å…±{num_epochs}ä¸ªå‘¨æœŸï¼Œæ‰¹æ¬¡å¤§å°:{config.batch_size}")
    print_rank_0("="*50 + "\n")
    
    # å®Œæ•´è®­ç»ƒå¾ªç¯
    try:
        metrics = trainer.train(
            train_loader,
            sampler=sampler,
            num_epochs=num_epochs,
            log_dir=log_dir
        )
        
        # æ‰“å°è®­ç»ƒç»“æœ
        print_rank_0("\n" + "="*50)
        print_rank_0("è®­ç»ƒå®Œæˆï¼")
        if metrics and 'train_loss' in metrics and len(metrics['train_loss']) > 0:
            print_rank_0(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {metrics['train_loss'][-1]:.8f}")
        print_rank_0("="*50 + "\n")
        
    except KeyboardInterrupt:
        print_rank_0("\n\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­ï¼æ­£åœ¨ä¿å­˜å½“å‰æ¨¡å‹...")
        last_path = f"{trainer.run_checkpoint_dir}/last_model.pt"
        
        # æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for retry in range(max_retries):
            try:
                trainer.save_checkpoint(last_path)
                print_rank_0(f"âœ“ æœ€åæ¨¡å‹å·²ä¿å­˜ä¸º {last_path}")
                break
            except Exception as e:
                if retry < max_retries - 1:
                    print_rank_0(f"âš ï¸ ä¿å­˜æ¨¡å‹å¤±è´¥ (å°è¯• {retry + 1}/{max_retries}): {str(e)}")
                    print_rank_0("ğŸ”„ ç­‰å¾…1ç§’åé‡è¯•...")
                    time.sleep(1)
                    torch.cuda.empty_cache()
                    gc.collect()
                else:
                    print_rank_0(f"âŒ ä¿å­˜æ¨¡å‹æœ€ç»ˆå¤±è´¥: {str(e)}")
        
        print_rank_0(f"æœ€ä½³æ¨¡å‹ä½ç½®: {trainer.run_checkpoint_dir}/best_model.pt (æŸå¤±: {trainer.best_loss:.8f})")
        print_rank_0(f"è¿è¡Œæ–‡ä»¶å¤¹: {trainer.run_checkpoint_dir}")
    
    # æ¸…ç†DDPç¯å¢ƒ
    cleanup_ddp()
